{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Ufs5t3YMhgt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#%matplotlib nbagg\n",
    "#%matplotlib inline\n",
    "\n",
    "import  matplotlib.pyplot as plt\n",
    "import matplotlib.backends.backend_pdf\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 8]\n",
    "import matplotlib.pylab as pylab\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (7, 5),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('xtick', labelsize='x-small')\n",
    "plt.rc('ytick', labelsize='x-small')\n",
    "pylab.rcParams.update(params)\n",
    "\n",
    "#plt.rcParams['xtick.color']='white'\n",
    "#plt.rcParams['ytick.color']='white'\n",
    "#plt.rcParams['axes.labelcolor']='white'\n",
    "#plt.rcParams['axes.titlecolor']='white'\n",
    "#plt.rcParams['axes.facecolor']='white'\n",
    "#%matplotlib notebook\n",
    "\n",
    "import statistics as stats\n",
    "from scipy.optimize import curve_fit\n",
    "from os import remove\n",
    "import os #para trabajar con directorios y carpetas\n",
    "import os.path #para determinar si existe una carpeta\n",
    "import shutil #para eliminar carpetas que tengan archivos adentro o mover archivos\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy import interpolate\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "#from astroML.plotting import setup_text_plots\n",
    "#setup_text_plots(fontsize=15, usetex=False)\n",
    "\n",
    "#ax.tick_params(direction='in', length=10, width=2, colors='black',\n",
    " #      bottom=1, top=1, left=1, right=1,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1688140445859,
     "user": {
      "displayName": "Mauricio Ramirez",
      "userId": "09361500070968174350"
     },
     "user_tz": 240
    },
    "id": "aPr6r0qmMhgy",
    "outputId": "0ed7e323-6c5c-4df1-b0f8-a6d12b3be17d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WdEvaPG9Mhgz"
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import time\n",
    "\n",
    "#notebook_name = \"Funciones_colab.ipynb\" # Reemplaza \"nombre_del_notebook.ipynb\" con el nombre de tu notebook\n",
    "#notebook_path = os.path.abspath(notebook_name)\n",
    "#notebook_path = os.path.join(os.getcwd(),'Codes/Funciones_colab.ipynb')#os.path.abspath(\"Codes/Funciones_colab.ipynb\")\n",
    "\n",
    "#print(\"Último guardado:\", time.ctime(os.path.getmtime(notebook_path)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cUZ8gpJgMhg1"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import subprocess\n",
    "\n",
    "def import_with_install(package):\n",
    "    \"\"\"\n",
    "    Intenta importar un paquete, y si falla, lo instala con pip3\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if package ==\"POT\":\n",
    "            importlib.import_module(\"ot\")\n",
    "        else:\n",
    "            importlib.import_module(package)\n",
    "\n",
    "    except ImportError:\n",
    "        print(f\"{package} no está instalado, se procederá a instalarlo...\")\n",
    "        try:\n",
    "            subprocess.check_call(['pip3', 'install', package])\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(f\"No se pudo instalar {package}. Por favor, instale el paquete manualmente.\")\n",
    "            return\n",
    "        print(f\"{package} se ha instalado correctamente.\")\n",
    "    finally:\n",
    "        if package ==\"POT\":\n",
    "            globals()[package] = importlib.import_module(\"ot\")\n",
    "        else:\n",
    "            globals()[package] = importlib.import_module(package)\n",
    "\n",
    "import_with_install('POT')\n",
    "import_with_install('IPython')\n",
    "#import_with_install('specutils')\n",
    "from ot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Whoz9DEcT2r1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gd_pfNfRMhg2"
   },
   "outputs": [],
   "source": [
    "def remove_filter(name,FILTRO,filtro):\n",
    "    for i in range(len(filtro)):\n",
    "        if filtro[i]==name:\n",
    "            #c.append(i)\n",
    "            FILTRO.pop(i)\n",
    "            filtro.pop(i)\n",
    "            break\n",
    "\n",
    "def remove_spec(name):\n",
    "     for i in range(len(spec)):\n",
    "        if spec[i]==name:\n",
    "            #c.append(i)\n",
    "            ESPECTRO.pop(i)\n",
    "            spec.pop(i)\n",
    "            DJ_SPEC.pop(i)\n",
    "            datos_espectros_spline.pop(i)\n",
    "            break\n",
    "\n",
    "def rms(x,parametros):\n",
    "    #print(x)\n",
    "    promedio=np.mean(x)\n",
    "    #promedio\n",
    "    residuales=x-promedio\n",
    "    l=residuales**2\n",
    "    #print(residuales)\n",
    "    val=np.sqrt(sum(l)/(len(x)-parametros))\n",
    "    return val\n",
    "\n",
    "def L1(x):\n",
    "    mediana=np.median(x)\n",
    "    residuales=abs(x-mediana)\n",
    "    val=np.median(residuales)\n",
    "    return val\n",
    "\n",
    "\n",
    "\n",
    "def maximun_light_curve(FILTRO,filtro): #arrelgo con los datos de todos los filtros, el nombre de los filtros\n",
    "    plt.style.use('classic')\n",
    "    maximos=[]\n",
    "    for j in range(len(FILTRO)):\n",
    "        like=1\n",
    "        while like==1:\n",
    "            DJ=[]\n",
    "            flux=[]\n",
    "            fluxerr=[]\n",
    "            for i in range(len(FILTRO[j])):\n",
    "\n",
    "                DJ.append(np.float(FILTRO[j][i][0]))\n",
    "                flux.append(np.float(FILTRO[j][i][1]))\n",
    "\n",
    "\n",
    "                #necesitamos las barras de error\n",
    "                fluxerr.append(np.float(FILTRO[j][i][2]))\n",
    "            xerr=np.zeros(len(flux)) #porque no hay error en X\n",
    "\n",
    "\n",
    "\n",
    "            plt.errorbar(DJ, flux, fluxerr,xerr,'.','g')\n",
    "            plt.grid()\n",
    "            plt.xlabel('Dia Juliano')\n",
    "            plt.ylabel('FLUJO')\n",
    "            plt.title('Curva de Luz filtro '+str(filtro[j]))\n",
    "            plt.show()\n",
    "\n",
    "            #-----------------------------------------\n",
    "            #primero creamos el dia juliano para el polyfit\n",
    "\n",
    "            JDpl=[]\n",
    "            fluxpl=[]\n",
    "            flux_errpl=[]\n",
    "            a=0\n",
    "            print('AHORA SE PROCEDE A HACER EL FIT AL REDEDOR DEL MAXIMO DE LA SUPER NOVA')\n",
    "            JDpl_menor=float(input('Ingrese cota inferior para el polifit   '))\n",
    "            JDpl_mayor=float(input('Ingrese cota superior para el polifit   '))\n",
    "            while a==0:\n",
    "                for i in range(len(DJ)):\n",
    "\n",
    "                    if DJ[i] >= JDpl_mayor:\n",
    "                            break\n",
    "                    if DJ[i]>=JDpl_menor:\n",
    "                        JDpl.append(DJ[i])\n",
    "                        fluxpl.append(flux[i])\n",
    "                        flux_errpl.append(fluxerr[i])\n",
    "\n",
    "                a=len(JDpl)\n",
    "                if a==0:\n",
    "                    print('El rango escogido no tiene valores ')\n",
    "                    JDpl_menor=float(input('Ingrese cota inferior para el polifit   '))\n",
    "                    JDpl_mayor=float(input('Ingrese cota superior para el polifit   '))\n",
    "\n",
    "            #sacamos los weights------------------------------------\n",
    "            W=[]\n",
    "            for i in range(len(flux_errpl)):\n",
    "                w=np.float(1/flux_errpl[i])\n",
    "                W.append(w)\n",
    "\n",
    "\n",
    "\n",
    "            par2=np.polyfit(JDpl,fluxpl,2,w=W)\n",
    "\n",
    "\n",
    "            #--------------------------------------------------\n",
    "            #calculamos el maximo con el criterio de la 2da derivada\n",
    "\n",
    "            #para gradoo 2 es mas facil:\n",
    "            DJ_max2=-par2[1]/(2*par2[0])\n",
    "            print('EL dia juliano del maximo para grado 2 es: ',DJ_max2)\n",
    "            Flux_max2=par2[0]*DJ_max2**2+par2[1]*DJ_max2+par2[2]\n",
    "            print('EL Flujo maximo para grado 2 es: ',Flux_max2)\n",
    "\n",
    "            #---------------------------------------------------\n",
    "            #para grado 3 tenemos dos soluciones porque el punto cero me da una formula cuadratica\n",
    "\n",
    "            par3=np.polyfit(JDpl,fluxpl,3,w=W)\n",
    "            a=par3[0]\n",
    "            print(type(a),'el tipo de a')\n",
    "            b=par3[1]\n",
    "            c=par3[2]\n",
    "           # x1=np.float((-2*par3[1]+((-2*par3[1])**2-(4*3*par3[0]*par3[2]))**0.5)/(2*3*par3[0]))\n",
    "            x1=np.float((-2*b+((-2*b)**2-(4*3*a*c))**0.5)/(2*3*a))\n",
    "\n",
    "            x2=(-2*par3[1]-((-2*par3[1])**2-(4*3*par3[0]*par3[2]))**0.5)/(2*3*par3[0])\n",
    "\n",
    "            #print ('el valor de x1 es\t:',x1)\n",
    "            #print ('el valor de x2 es\t:',x2)\n",
    "\n",
    "            signo=6*par3[0]*x1+2*par3[1]\n",
    "            signo2=6*par3[0]*x2+2*par3[1]\n",
    "            print('x1',x1)\n",
    "            print(type(x1))\n",
    "            print('x2 ',x2)\n",
    "            print('signo' ,signo)\n",
    "            print('signo2 ',signo2)\n",
    "\n",
    "            global DJ_max3\n",
    "\n",
    "            if signo==' nan':\n",
    "                DJ_max3=DJ_max2\n",
    "                print('No tiene maximo en polinomio grado 3, por lo que es el mismo para grado 2',DJ_max3)\n",
    "\n",
    "\n",
    "            elif signo<0:\n",
    "                #print ('x1 es un maximo')\n",
    "                DJ_max3=x1\n",
    "                print ('EL dia juliano del maximo para grado 3 es\t:',DJ_max3)\n",
    "\n",
    "            elif signo2<0:\n",
    "                #print ('x2 es un maximo')\n",
    "                DJ_max3=x2\n",
    "                print ('EL dia juliano del maximo para grado 3 es',DJ_max3)\n",
    "\n",
    "\n",
    "            Flux_max3=par3[0]*DJ_max3**3+par3[1]*DJ_max3**2+par3[2]*DJ_max3+par3[3]\n",
    "            print('EL Flujo maximo para grado 3 es: ',Flux_max3)\n",
    "\n",
    "\n",
    "            #-----------------------------------------------------------------------------\n",
    "\n",
    "            fig1=plt.figure(1)\n",
    "            plt.figure(figsize=(6,5))\n",
    "            xp=np.linspace(np.min(JDpl),np.max(JDpl),len(JDpl))\n",
    "            plt.plot(xp,np.polyval(par2,xp),color='orange',label='pol grado 2')\n",
    "            plt.plot(xp,np.polyval(par3,xp),'--',color='green',label='pol grado 3')\n",
    "\n",
    "\n",
    "\n",
    "            plt.scatter(JDpl,fluxpl)\n",
    "            plt.grid()\n",
    "            plt.xlabel('Dia Juliano')\n",
    "            plt.ylabel('FLUJO')\n",
    "            plt.title('Curva de Luz filtro '+str(filtro[j]))\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "            #------------------------------------------------------------------\n",
    "            DJ_zoom=[]\n",
    "            flux_zoom=[]\n",
    "\n",
    "            for i in range(len(DJ)):\n",
    "                if abs(DJ_max3-DJ[i])<=50:\n",
    "                    DJ_zoom.append(DJ[i])\n",
    "                    flux_zoom.append(flux[i])\n",
    "            #------------------------------------------------------------------\n",
    "\n",
    "            fig2=plt.figure(2)\n",
    "            plt.figure(figsize=(6,5))\n",
    "            xp=np.linspace(np.min(JDpl),np.max(JDpl),len(JDpl))\n",
    "            plt.plot(xp,np.polyval(par2,xp),color='orange',label='pol grado 2')\n",
    "            plt.plot(xp,np.polyval(par3,xp),'--',color='green',label='pol grado 3')\n",
    "\n",
    "\n",
    "\n",
    "            plt.scatter(DJ_zoom,flux_zoom)\n",
    "            plt.grid()\n",
    "            plt.xlabel('Dia Juliano')\n",
    "            plt.ylabel('FLUJO')\n",
    "            plt.title('Curva de Luz filtro '+str(filtro[j]))\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "            print('#########################################################################')\n",
    "\n",
    "\n",
    "\n",
    "            #-----------------------------------------------------\n",
    "            like=float(input('Ajuste correcto? o desea cambiar las fechas?: 1=cambiar 2=conservar '))\n",
    "            while(like!=1 and like!=2):\n",
    "                like=float(input('Ingrese 1 o 2: '))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            if like ==2:\n",
    "                guardar=float(input('Desea guardar el maximo de grado 2 o 3:  ' ))\n",
    "                while(guardar!=2 and guardar!=3):\n",
    "                    guardar=float(input('Ingrese 1 o 2: '))\n",
    "                if guardar==2:\n",
    "                    DJ_max=DJ_max2\n",
    "                elif guardar==3:\n",
    "                    DJ_max=DJ_max3\n",
    "\n",
    "\n",
    "                xp=np.linspace(np.min(JDpl),np.max(JDpl),len(JDpl))\n",
    "                eje_y=np.polyval(par2,xp)\n",
    "\n",
    "                file=open('Ajuste_curva_'+str(filtro[j]),'w')\n",
    "                #guardo el ajuste de la curva en un archivo de texto\n",
    "                file.write('#DATOS CURVA AJUSTADA\\n')\n",
    "                for i in range(len(xp)):\n",
    "                    file.write(str(xp[i])+'\\t'+str(eje_y[i])+'\\n')\n",
    "\n",
    "                file.write('\\n')\n",
    "                file.write('#DATOS A LOS CUALES SE AJUSTA LA CURVA\\n')\n",
    "\n",
    "                for ii in range(len(JDpl)):\n",
    "                    file.write(str(JDpl[ii])+'\\t'+str(fluxpl[ii])+'\\n')\n",
    "                file.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                maximos.append(DJ_max)\n",
    "    return maximos\n",
    "\n",
    "\n",
    "def data_curvas(path,rename=False): #funcion para leer los archivos de texto de los filtros\n",
    "    import pandas as pd\n",
    "    with open(path,'rt') as f2:\n",
    "        lineas= [linea.split() for linea in f2]\n",
    "    cantidad_filtros=0 #contador de filtros\n",
    "    filtro=[] #arreglo con los filtros\n",
    "    componente_filas=[] #me dice las componentes de las lineas en que estan los datos por filtro (ejemplo: filtro B de la 7\n",
    "    for i in range(len(lineas)):\n",
    "        if len(lineas[i])>=2:\n",
    "            if lineas[i][1]=='FILTER':\n",
    "                #print (lineas[i][2])\n",
    "                cantidad_filtros=cantidad_filtros+1\n",
    "                filtro.append(lineas[i][2])\n",
    "                componente_filas.append(i)\n",
    "\n",
    "\n",
    "    #print ('HAY UN TOTAL DE ',cantidad_filtros,' FILTROS')\n",
    "    #print (filtro)\n",
    "    #print (componente_filas)\n",
    "\n",
    "    FILTRO=[]\n",
    "    for j in range(len(componente_filas)):\n",
    "        nombre = \"filtro_\" + str(filtro[j])\n",
    "        #print (nombre)\n",
    "        filtro1=[]\n",
    "        if j==len(componente_filas)-1:\n",
    "            final=len(lineas)\n",
    "            lineas_filtro=np.arange(componente_filas[j]+2,final,1)\n",
    "            #print (lineas_filtro)\n",
    "            for i in lineas_filtro:\n",
    "                filtro1.append(lineas[i])\n",
    "                filtro1.append\n",
    "        else:\n",
    "            lineas_filtro=np.arange(componente_filas[j]+2,componente_filas[j+1]-1,1) #me dice las lineas que tengo q guardar por filtro\n",
    "            #print (lineas_filtro)\n",
    "            for i in lineas_filtro:\n",
    "                filtro1.append(lineas[i])\n",
    "\n",
    "        filtro1=pd.DataFrame(filtro1)\n",
    "        #print(filtro1)\n",
    "        filtro1[0] = filtro1[0].astype(float)\n",
    "        filtro1[1] = filtro1[1].astype(float)\n",
    "        filtro1[2]=filtro1[2].astype(float)\n",
    "\n",
    "        if rename==True:\n",
    "            filtro1 = filtro1.rename(columns={0: 'mjd', 1: 'flux'})\n",
    "\n",
    "        FILTRO.append(filtro1)\n",
    "        #print (filtro1)\n",
    "    return FILTRO,filtro #me retorna FILTRO donde estan los datos y filtro que es una lista con los filtros\n",
    "\n",
    "def GP(x,y,yerr,evaluar): #A la funcion se le ingresan los arreglos que se le realizara el proceso gaussiano, y donde quiero evaluar\n",
    "    from sklearn import gaussian_process\n",
    "    from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel\n",
    "    from sklearn.gaussian_process.kernels import (RBF, Matern, RationalQuadratic,\n",
    "                                              ExpSineSquared, DotProduct,\n",
    "                                              ConstantKernel)\n",
    "    kernel1=1.0 * RBF(length_scale=10,length_scale_bounds=(1e-20, 100000.0))     #Defino el kernel a utilizar\n",
    "\n",
    "    kernel3= Matern(length_scale=1.0, nu=1.5, length_scale_bounds=(1e-5, 1e5))\n",
    "\n",
    "    #-------------------Aplicamos el proceso Gaussiano-----------------------\n",
    "    X = x.reshape(-1, 1)                    #Redefinimos las dimensiones de X para que quede como 2d\n",
    "    X.shape\n",
    "\n",
    "    gp = gaussian_process.GaussianProcessRegressor(kernel=kernel1*kernel3, n_restarts_optimizer=9,alpha=yerr**2)  #llamamos la funcion del Gaussian Process\n",
    "    gp.fit(X, y)\n",
    "    #----------------------------------------------------------------------------------\n",
    "    #ahora creo los arreglos donde voy a evaluar mi proceso Gaussiano.\n",
    "\n",
    "    x_pred=np.array(evaluar).reshape(-1,1)\n",
    "\n",
    "    #x_pred2=np.linspace(min(x),max(x),1000000).reshape(-1,1)#por si quiero los intervalos de confianza en un futuro\n",
    "    #y_pred2,sigma2=gp.predict(x_pred2,return_std=True)\n",
    "\n",
    "    y_pred,sigma=gp.predict(x_pred,return_std=True)\n",
    "    return x_pred,y_pred,sigma\n",
    "\n",
    "\n",
    "def best_reg(A,M,weights):#entran todos los parametros que quiero calcular\n",
    "    #This function look for the best regularization term on the computation of the barycenter\n",
    "    # If the interpolation cant be done, this increase the regularization term\n",
    "    import math\n",
    "    import ot\n",
    "    global reg_def\n",
    "    a=np.arange(-7,-1,0.1)#-7,10,1 /-3,-2,1\n",
    "    for i in range(len(a)):\n",
    "        reg1=5*10**(a[i])\n",
    "        #print('regularization term:',reg1)\n",
    "        #you can choose use another method\n",
    "        #bary_wass1=ot.bregman.barycenter(A,M,reg1,weights,verbose=False,method='sinkhorn_stabilized',tau=1e250)\n",
    "        bary_wass1=ot.bregman.barycenter(A,M,reg1,weights,verbose=False,method='sinkhorn',numItermax =10)\n",
    "\n",
    "        cont=0\n",
    "        #print(bary_wass1)\n",
    "        for j in range(len(bary_wass1)):\n",
    "            if math.isnan(bary_wass1[j])==True or math.isinf(bary_wass1[j])==True:\n",
    "                  cont=cont+1\n",
    "        #print('a,index,cont,bary_wass:',a[i],i,cont,bary_wass1)\n",
    "        if cont==0:\n",
    "            reg_def=reg1\n",
    "            break\n",
    "        else:\n",
    "            #print(a[i])\n",
    "            reg_def=9999999999\n",
    "\n",
    "\n",
    "    return reg_def,bary_wass1\n",
    "\n",
    "def OT(a1,a2,alpha):#entran dos distribuciones y la cercanica de cada una\n",
    "    #%% parameters\n",
    "    import ot\n",
    "\n",
    "    n = len(a1)  # nb bins\n",
    "\n",
    "    # bin positions\n",
    "    x = np.arange(n, dtype=np.float64)\n",
    "\n",
    "    # creating matrix A containing all distributions\n",
    "    A = np.vstack((a1, a2)).T\n",
    "    n_distributions = A.shape[1]\n",
    "\n",
    "    # loss matrix + normalization\n",
    "    M = ot.utils.dist0(n)\n",
    "    #print(M)\n",
    "    M /= M.max()\n",
    "    #print(M)\n",
    "\n",
    "    #%% barycenter computation\n",
    "\n",
    "    #alpha = cercania#0.5  # 0<=alpha<=1\n",
    "    weights = np.array([ 1-alpha, alpha])\n",
    "\n",
    "    # l2bary\n",
    "    #bary_l2 = A.dot(weights)\n",
    "\n",
    "    # regularized wasserstein\n",
    "\n",
    "    reg,bary_wass=best_reg(A,M,weights)\n",
    "    #reg = 1*10**(-3) #mientras mas pequeño este numero parece mejorar el ajuste..\n",
    "    #ot.tic()\n",
    "    #bary_wass = ot.bregman.barycenter(A, M, reg, weights)\n",
    "    #ot.toc()\n",
    "\n",
    "    # linear programming barycenter\n",
    "    #ot.tic()\n",
    "    #bary_wass2 = ot.lp.barycenter(A, M, weights, solver='interior-point', verbose=True)\n",
    "    #ot.toc()\n",
    "    return bary_wass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zgk3uxWHMhg_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oNZjQ2mQMhg_"
   },
   "outputs": [],
   "source": [
    "#Ahora tengo que aplicar la fotometria sintetica\n",
    "#vamos a crear una funcion para calcular la fotometria sintetica\n",
    "\n",
    "def Syntetic_photometry(xspec,yspec,xband,yband): #En Amstrong\n",
    "        contador=0\n",
    "        S_lambda=[] #Flujo del espectro en la interseccion\n",
    "        F_lambda=[] #flujo de la banda en la interseccion\n",
    "        x_lambda=[]\n",
    "\n",
    "        componente_spectra=[]\n",
    "        componente_band=[]\n",
    "        xspec=np.array(xspec)\n",
    "        yspex=np.array(yspec)\n",
    "        xband=np.array(xband)\n",
    "        yband=np.array(yband)\n",
    "        #xspec=xnew\n",
    "        for z in range(len(xband)):\n",
    "            if xband[z] in xspec:\n",
    "                x_lambda.append(xband[z]) #esta es la lista con las longitudes de onda que se interceptan\n",
    "                contador=contador+1\n",
    "\n",
    "\n",
    "        #----------------------calculo de la interseccion del espectro-------------------------------\n",
    "        for zz in range(len(xspec)):\n",
    "            for m in range(len(x_lambda)):\n",
    "                if x_lambda[m]==xspec[zz]:\n",
    "                    componente_spectra.append(zz)\n",
    "\n",
    "\n",
    "        for componente in componente_spectra:\n",
    "            S_lambda.append(yspec[componente])\n",
    "\n",
    "        #----------------------calculo de la interseccion de la banda--------------------------------\n",
    "        for cc in range(len(xband)):\n",
    "            for m in range(len(x_lambda)):\n",
    "                if x_lambda[m]==xband[cc]:\n",
    "                    componente_band.append(cc)\n",
    "\n",
    "\n",
    "        for componente in componente_band:\n",
    "            F_lambda.append(yband[componente])\n",
    "\n",
    "        #-------------------------------------------------------\n",
    "\n",
    "        area_norm_tot=0\n",
    "        area_band_tot=0\n",
    "        # AHORA VAMOS A CALCULAR EL AREA DE LA RESPUESTA PARA NORMALIZAR\n",
    "\n",
    "        #-------FORMA1---------------------------------\n",
    "        #for ii in range(len(x_lambda)): #area para normalizar\n",
    "            #area_normalizar=1*F_lambda[ii]*x_lambda[ii]\n",
    "            #area_norm_tot=area_normalizar+area_norm_tot\n",
    "        #-------FORMA2----------------------------\n",
    "        for ii in range(len(xband)):\n",
    "            area_normalizar=1*yband[ii]*xband[ii]\n",
    "            area_norm_tot=area_normalizar+area_norm_tot\n",
    "\n",
    "            #--------para sacar porcentaje--------\n",
    "            area_band=1*yband[ii]#Esta es sin mutiplicar la longitud de onda para sacar porcentaje\n",
    "            area_band_tot=area_band+area_band_tot\n",
    "\n",
    "        #---Ahora calculamo el area de la interseccion\n",
    "        areatotal1=0\n",
    "        area_inter_banda_total=0\n",
    "        for l in range(len(x_lambda)): #area de la banda\n",
    "            #b1=x_lambda[l]\n",
    "            #b2=x_lambda[l+1]\n",
    "            #base=b2-b1\n",
    "            #h1=F_lambda[l]*S_lambda[l]\n",
    "            #h2=F_lambda[l+1]*S_lambda[l+1]\n",
    "            #prom=(h1+h2)/2\n",
    "            area=1*(F_lambda[l]*S_lambda[l])*x_lambda[l]\n",
    "            areatotal1=area+areatotal1\n",
    "\n",
    "            #------para sacar porcentaje-----------\n",
    "            area_inter_banda=1*F_lambda[l]\n",
    "            area_inter_banda_total=area_inter_banda_total+area_inter_banda\n",
    "\n",
    "        print(area_inter_banda_total,area_band_tot)\n",
    "        porcentaje= 100*(area_inter_banda_total/area_band_tot)\n",
    "        print('El filtro cubre un ',porcentaje,'%')\n",
    "\n",
    "        total=areatotal1/area_norm_tot#*areatotal2\n",
    "        print('num|den')\n",
    "        print(areatotal1,area_norm_tot)\n",
    "\n",
    "        return total,porcentaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "itOhwJFwMhhB"
   },
   "outputs": [],
   "source": [
    "def Syntetic_photometry_v2(xspec,yspec,xband,yband):\n",
    "    #recibe pandas dataframe o arrays, y calcula la inrterseccion\n",
    "    #pueden ser de distinto largo y la respuesta de la banda se adapta a la grilla del espectro con regrid\n",
    "\n",
    "    from sklearn.metrics import auc\n",
    "\n",
    "    ######################################################################\n",
    "    # AHORA VAMOS A CALCULAR EL AREA DE LA RESPUESTA PARA NORMALIZAR\n",
    "    a_banda=auc(xband,yband) #esta es el area de la banda\n",
    "\n",
    "    #necesitamos el area de la interseccion##############################\n",
    "    import scipy\n",
    "    from scipy.interpolate import griddata\n",
    "    regrid=scipy.interpolate.griddata(xband, yband,xspec, method='linear', rescale=False)\n",
    "    df_regrid=pd.DataFrame({'wave':xspec,'response':regrid})\n",
    "    df_regrid = df_regrid.dropna(how='any') #eliminamos los nan\n",
    "\n",
    "    try:\n",
    "        a_inter=auc(df_regrid['wave'],df_regrid['response'])\n",
    "    except ValueError:\n",
    "        return 0,0\n",
    "    #####################################################################\n",
    "    porcentaje=a_inter/a_banda\n",
    "    #print(a_inter,a_banda)\n",
    "    #print('porcentaje:',a_inter/a_banda)\n",
    "    spec1_df=pd.DataFrame({'wave':xspec,'flux':yspec})\n",
    "    #ahora calculamos el numerador de la integral\n",
    "    merge = pd.merge(spec1_df, df_regrid, how='inner', on=['wave']) #mismo q df_regrid pero con el flujo del spec\n",
    "\n",
    "    num=auc(merge['wave'],merge['flux']*merge['response']*merge['wave'])\n",
    "\n",
    "    #calculamos el denominador\n",
    "\n",
    "    den=auc(xband,yband*xband) #este es el numerador para normalizar\n",
    "\n",
    "    total_=num/den\n",
    "    #print('area :',total_, 'porcentaje:',porcentaje)\n",
    "    #print('num|den')\n",
    "    #print(num,den)\n",
    "    \n",
    "\n",
    "    return total_,porcentaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZzYjozBNMhhC"
   },
   "outputs": [],
   "source": [
    "def planckiana(lambda_,T,k):        #el k es una constante de normalizacion lambda debe estar en micrometros\n",
    "    import math\n",
    "    h=6.626070150e-34   #En J*s      #6.626070150e-27 # e ergs*s\n",
    "    c=3e8                       #velocidad de la luz en m*s\n",
    "    cte= 1.380649e-23  #en J/K      #1.380649e-16 #constante de boltzman en ergs/K\n",
    "\n",
    "    numerador=(2.0*h*(c**2))\n",
    "    denominador=(lambda_**5)*(np.exp(h*c/(lambda_*cte*T))-1)\n",
    "    B_lambda=numerador/denominador\n",
    "    return k*B_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dd5yDs22MhhD"
   },
   "outputs": [],
   "source": [
    "def effective_wavelength(xspec,yspec,xband,yband):\n",
    "        contador=0\n",
    "        S_lambda=[] #Flujo del espectro en la interseccion\n",
    "        F_lambda=[] #flujo de la banda en la interseccion\n",
    "        x_lambda=[]\n",
    "\n",
    "        componente_spectra=[]\n",
    "        componente_band=[]\n",
    "\n",
    "        #xspec=xnew\n",
    "        for z in range(len(xband)):\n",
    "            if xband[z] in xspec:\n",
    "                x_lambda.append(xband[z]) #esta es la lista con las longitudes de onda que se interceptan\n",
    "                contador=contador+1\n",
    "\n",
    "\n",
    "        #----------------------calculo de la interseccion del espectro-------------------------------\n",
    "        for zz in range(len(xspec)):\n",
    "            for m in range(len(x_lambda)):\n",
    "                if x_lambda[m]==xspec[zz]:\n",
    "                    componente_spectra.append(zz)\n",
    "\n",
    "\n",
    "        for componente in componente_spectra:\n",
    "            S_lambda.append(yspec[componente])\n",
    "\n",
    "        #----------------------calculo de la interseccion de la banda--------------------------------\n",
    "        for cc in range(len(xband)):\n",
    "            for m in range(len(x_lambda)):\n",
    "                if x_lambda[m]==xband[cc]:\n",
    "                    componente_band.append(cc)\n",
    "\n",
    "\n",
    "        for componente in componente_band:\n",
    "            F_lambda.append(yband[componente])\n",
    "\n",
    "        #-------------------------------------------------------\n",
    "\n",
    "        area_norm_tot=0\n",
    "        area_band_tot=0\n",
    "\n",
    "\n",
    "        #---Ahora calculamo el area de la interseccion\n",
    "        areatotal1=0\n",
    "        area_inter_banda_total=0\n",
    "        for l in range(len(x_lambda)): #area de la banda\n",
    "            #b1=x_lambda[l]\n",
    "            #b2=x_lambda[l+1]\n",
    "            #base=b2-b1\n",
    "            #h1=F_lambda[l]*S_lambda[l]\n",
    "            #h2=F_lambda[l+1]*S_lambda[l+1]\n",
    "            #prom=(h1+h2)/2\n",
    "            area=1*(F_lambda[l]*S_lambda[l])*x_lambda[l]\n",
    "            areatotal1=area+areatotal1\n",
    "\n",
    "            area_normalizar=1*(F_lambda[l]*S_lambda[l])\n",
    "            area_norm_tot=area_normalizar+area_norm_tot\n",
    "            #----------para sacar porcentaje\n",
    "            area_inter_banda=1*F_lambda[l]\n",
    "            area_inter_banda_total=area_inter_banda_total+area_inter_banda\n",
    "\n",
    "        # AHORA VAMOS A CALCULAR EL AREA DE LA RESPUESTA PARA NORMALIZAR\n",
    "\n",
    "        #-------FORMA1---------------------------------\n",
    "        #for ii in range(len(x_lambda)): #area para normalizar\n",
    "            #area_normalizar=1*F_lambda[ii]*x_lambda[ii]\n",
    "            #area_norm_tot=area_normalizar+area_norm_tot\n",
    "        #-------FORMA2----------------------------\n",
    "        for ii in range(len(xband)):\n",
    "            #area_normalizar=1*(F_lambda[l]*S_lambda[l])\n",
    "            #area_norm_tot=area_normalizar+area_norm_tot\n",
    "\n",
    "            #-----------\n",
    "            area_band=1*yband[ii]#Esta es sin mutiplicar la longitud de onda para sacar porcentaje\n",
    "            area_band_tot=area_band+area_band_tot\n",
    "\n",
    "        print(areatotal1,area_norm_tot)\n",
    "        #print(area_inter_banda_total,area_band_tot)\n",
    "        porcentaje= 100*(area_inter_banda_total/area_band_tot)\n",
    "        print('El filtro cubre un ',porcentaje,'%')\n",
    "\n",
    "        total=areatotal1/area_norm_tot#*areatotal2\n",
    "        print(total)\n",
    "        return total,porcentaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wrXO5sHuMhhE"
   },
   "outputs": [],
   "source": [
    "\n",
    "def effective_wavelength_same_length(xspec,yspec,xband,yband):\n",
    "\n",
    "        areatotal1=0\n",
    "        area_inter_banda_total=0\n",
    "        area_normalizar=0\n",
    "        area_norm_tot=0\n",
    "\n",
    "        xspec=np.array(xspec)\n",
    "        yspex=np.array(yspec)\n",
    "        xband=np.array(xband)\n",
    "        yband=np.array(yband)\n",
    "\n",
    "        for l in range(len(xspec)): #area de la banda\n",
    "            area=1*(yspec[l]*yband[l])*xspec[l]\n",
    "            areatotal1=area+areatotal1\n",
    "\n",
    "            area_normalizar=1*(yspec[l]*yband[l])\n",
    "            area_norm_tot=area_normalizar+area_norm_tot\n",
    "            #----------para sacar porcentaje\n",
    "            #area_inter_banda=1*F_lambda[l]\n",
    "            #area_inter_banda_total=area_inter_banda_total+area_inter_banda\n",
    "\n",
    "        print(areatotal1,area_norm_tot)\n",
    "        #print(area_inter_banda_total,area_band_tot)\n",
    "        #porcentaje= 100*(area_inter_banda_total/area_band_tot)\n",
    "        #print('El filtro cubre un ',porcentaje,'%')\n",
    "\n",
    "        total=areatotal1/area_norm_tot#*areatotal2\n",
    "        print(total)\n",
    "        return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CAhDOSpUMhhG"
   },
   "outputs": [],
   "source": [
    "def read_spec(path):\n",
    "    with open(path,'r') as f2:\n",
    "        espectro_lineas= [linea.split() for linea in f2]\n",
    "\n",
    "    componente_filas_spec=[]\n",
    "    spec=[]\n",
    "    fases=[]\n",
    "\n",
    "    for i in range(len(espectro_lineas)):\n",
    "        if len(espectro_lineas[i])>1:\n",
    "            if 'SPEC' in espectro_lineas[i][1]:\n",
    "                componente_filas_spec.append(i)  #me dice en que componente esta el spectro de la posicion\n",
    "                fase=espectro_lineas[i][2]\n",
    "                fase=float(fase.strip('PHASE='))\n",
    "                spec.append(float('%.3f'%fase))\n",
    "                fases=spec\n",
    "\n",
    "    ESPECTRO=[]\n",
    "    for j in range(len(componente_filas_spec)):\n",
    "        nombre_spec = str(spec[j])\n",
    "        print (nombre_spec)\n",
    "        espectro1=[]\n",
    "        if j==len(componente_filas_spec)-1:\n",
    "            final=len(espectro_lineas)\n",
    "            lineas_espectro=np.arange(componente_filas_spec[j]+2,final,1)\n",
    "            #print (lineas_espectro)\n",
    "            for i in lineas_espectro:\n",
    "                if float(espectro_lineas[i][1])!=0:\n",
    "                    espectro1.append(espectro_lineas[i])\n",
    "\n",
    "        else:\n",
    "            lineas_espectro=np.arange(componente_filas_spec[j]+2,componente_filas_spec[j+1]-1,1) #me dice las lineas que tengo q guardar por filtro\n",
    "            #print (lineas_espectro)\n",
    "            for i in lineas_espectro:\n",
    "\n",
    "                if len(espectro_lineas[i])==0:\n",
    "                    break\n",
    "\n",
    "                if float(espectro_lineas[i][1])!=0:\n",
    "                    espectro1.append(espectro_lineas[i])\n",
    "        ESPECTRO.append(espectro1)\n",
    "    #print(fases)\n",
    "    return ESPECTRO,fases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gu_w3UVWMhhG"
   },
   "outputs": [],
   "source": [
    "def leer_spec(path,ot=False,MJD=False,as_pandas=False,compress=False):\n",
    "\n",
    "    if compress==True:\n",
    "        import gzip\n",
    "\n",
    "        with gzip.open(path, 'rb') as f2:\n",
    "            espectro_lineas= [linea.split() for linea in f2]\n",
    "    else:\n",
    "        with open(path,'rt') as f2:\n",
    "            espectro_lineas= [linea.split() for linea in f2]\n",
    "\n",
    "    componente_filas_spec=[]\n",
    "    spec=[]\n",
    "    fases=[]\n",
    "    iniciales=[]\n",
    "    finales=[]\n",
    "    alphas=[]\n",
    "    for i in range(len(espectro_lineas)):\n",
    "        if len(espectro_lineas[i])>1:\n",
    "            if 'SPEC' in espectro_lineas[i][1] and 'NSPEC' not in espectro_lineas[i][1]:\n",
    "                componente_filas_spec.append(i)  #me dice en que componente esta el spectro de la posicion\n",
    "\n",
    "            if 'time:' == espectro_lineas[i][1] :\n",
    "                fase=espectro_lineas[i][2]\n",
    "\n",
    "                spec.append(float(fase)) #le saque el round porque me daba espectros repetidos cuando, si lo quiero poner deberia quiza usar un drop duplicates en el\n",
    "                                            #calculo del rms y mad\n",
    "                fases=spec\n",
    "                #print(fase)\n",
    "            else:\n",
    "                if MJD==True:\n",
    "                    if len(espectro_lineas[i])==5:\n",
    "                        if 'MJD' in espectro_lineas[i][4] and 'SPEC' in espectro_lineas[i]:\n",
    "                            fase=espectro_lineas[i][4]\n",
    "                            fase=float(fase.strip('MJD='))\n",
    "                            spec.append(fase) #saque el round\n",
    "                            fases=spec\n",
    "            if ot==True:\n",
    "                if 'ini:' in espectro_lineas[i][1]:\n",
    "                    inicial=espectro_lineas[i][2]\n",
    "                    iniciales.append(float('%.3f'%float(inicial)))\n",
    "                if 'fin:' in espectro_lineas[i][1]:\n",
    "                    final=espectro_lineas[i][2]\n",
    "                    finales.append(float('%.3f'%float(final)))\n",
    "                if 'alpha:' in espectro_lineas[i][1]:\n",
    "                    alpha=espectro_lineas[i][2]\n",
    "                    alphas.append(float('%.3f'%float(alpha)))\n",
    "\n",
    "\n",
    "    ESPECTRO=[]\n",
    "    for j in range(len(componente_filas_spec)):\n",
    "        #nombre_spec = str(spec[j])\n",
    "        #print (nombre_spec)\n",
    "        espectro1=[]\n",
    "        if j==len(componente_filas_spec)-1:\n",
    "            final=len(espectro_lineas)\n",
    "            lineas_espectro=np.arange(componente_filas_spec[j]+1,final,1)\n",
    "            #print (lineas_espectro)\n",
    "            for i in lineas_espectro:\n",
    "                if espectro_lineas[i][1]=='WAVE':\n",
    "                    continue\n",
    "                if float(espectro_lineas[i][1])!=0:\n",
    "                    espectro1.append(espectro_lineas[i])\n",
    "\n",
    "        else:\n",
    "            if ot==True:\n",
    "                res=4 #esto es para que lea los archivos bien ya que los OT tienen info extra\n",
    "            else:\n",
    "                res=1\n",
    "            lineas_espectro=np.arange(componente_filas_spec[j]+1,componente_filas_spec[j+1]-res,1) #me dice las lineas que tengo q guardar por filtro\n",
    "            #print (lineas_espectro)\n",
    "            for i in lineas_espectro:\n",
    "\n",
    "                if len(espectro_lineas[i])==0:\n",
    "                    break\n",
    "                if espectro_lineas[i][1]=='WAVE':\n",
    "                    continue\n",
    "\n",
    "                if float(espectro_lineas[i][1])!=0:\n",
    "                    espectro1.append(espectro_lineas[i])\n",
    "        if as_pandas==True:\n",
    "            #print(len(espectro1[0]))\n",
    "            #print(espectro1)\n",
    "            try:\n",
    "                if len(espectro1[0])==2:\n",
    "                    espectro1=pd.DataFrame(espectro1,dtype=\"float64\",columns=[\"wave\",\"flux\"])\n",
    "                elif len(espectro1[0])==3:\n",
    "                    espectro1=pd.DataFrame(espectro1,dtype=\"float64\",columns=[\"wave\",\"flux\",'fluxerr'])\n",
    "                else:\n",
    "                    return print('Imposible llevar a pandas, revisa las columnas')\n",
    "            except:\n",
    "                espectro1=pd.DataFrame(espectro1,dtype=\"float64\",columns=[\"wave\",\"flux\"])\n",
    "\n",
    "        ESPECTRO.append(espectro1)\n",
    "    #print('Phases:',fases)\n",
    "\n",
    "    if ot==True:\n",
    "        return ESPECTRO,fases,iniciales,finales,alphas\n",
    "    else:\n",
    "        return ESPECTRO,fases\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "def leer_spectra_OT(ruta_archivo):\n",
    "    with open(ruta_archivo) as archivo:\n",
    "        lector_csv = csv.reader(archivo, delimiter='\\t',skipinitialspace=True)\n",
    "        ESPECTRO = []\n",
    "        fases = []\n",
    "        iniciales = []\n",
    "        finales = []\n",
    "        alphas = []\n",
    "        espectro_actual = []\n",
    "        for linea in lector_csv:\n",
    "\n",
    "            if not linea:\n",
    "                continue\n",
    "            if linea[0].startswith('#'):\n",
    "                if 'SPEC' in linea[0] and len(espectro_actual)>0:\n",
    "                    ESPECTRO.append(pd.DataFrame(espectro_actual,columns=['wave','flux']))\n",
    "                    espectro_actual = []\n",
    "                elif 'ini' in linea[0]:\n",
    "                    iniciales.append(float(linea[0].split(':')[1]))\n",
    "                elif 'fin' in linea[0]:\n",
    "                    finales.append(float(linea[0].split(':')[1]))\n",
    "                elif 'alpha' in linea[0]:\n",
    "                    alphas.append(float(linea[0].split(':')[1]))\n",
    "                elif 'time' in linea[0]:\n",
    "                    fases.append(float(linea[0].split(':')[1]))\n",
    "            else:\n",
    "                #print(linea)\n",
    "                linea=list(filter(None, linea)) #para eliminar cuando empieza con un elemento vacio en el espectro\n",
    "                #print(linea)\n",
    "                longitud_onda = float(linea[0])\n",
    "                flujo = float(linea[1])\n",
    "                espectro_actual.append((longitud_onda, flujo))\n",
    "\n",
    "        ESPECTRO.append(pd.DataFrame(espectro_actual,columns=['wave','flux'])) #este es para el ultimo espectro\n",
    "        return ESPECTRO, fases, iniciales, finales, alphas\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RvEfBoqoMhhI"
   },
   "outputs": [],
   "source": [
    "def sin_vs_obs(syntetic_df,V,FILTRO_,plot_fases=[],plot_syn=True,fig_title='',K=False,ot=False,mag_to_flux=False,interactive=False,get_ALR=False,use_cte=True,df_othersyn=[]):\n",
    "    #el V es un string con el nombre de la banda\n",
    "    #recive la curva de luz sintetica y la observada\n",
    "\n",
    "    cteB=6.460803024157998e-09\n",
    "    cteV=3.67558126207669e-09\n",
    "    cteR=2.2319872881446082e-09\n",
    "    cteI=1.1769629663231628e-09\n",
    "    cteU=4.346809582387867e-09\n",
    "\n",
    "    cteu=9.512689427618875e-09#859.5e-11\n",
    "    cteg=4.791168585588861e-09#466.9e-11\n",
    "    cter=2.818556152283821e-09#278.0e-11\n",
    "    ctei=1.9069984363571034e-09#185.2e-11\n",
    "    ctez=1.413365541656362e-09#131.5e-11\n",
    "    arr_ctes=['cteB','cteV','cteR','cteI','cteU','cteu','cteg','cter','ctei','ctez']\n",
    "    arr_val_ctes=[cteB,cteV,cteR,cteI,cteU,cteu,cteg,cter,ctei,ctez]\n",
    "\n",
    "              #poner el indice de el plot en el que esta la curva V\n",
    "\n",
    "    DJ=[]\n",
    "    flux=[]\n",
    "    flux_err=[]\n",
    "    constante='cte'+V #pongo V pero es cualquier banda\n",
    "    #print (constante)\n",
    "    for jj in range(len(arr_ctes)):\n",
    "            if constante==arr_ctes[jj]: #recorremos el arreglo de constantes en busca de la que le corresponde\n",
    "                print (constante,arr_ctes[jj],arr_val_ctes[jj])\n",
    "                mul=arr_val_ctes[jj]\n",
    "\n",
    "    if use_cte==False:\n",
    "        mul=1\n",
    "\n",
    "\n",
    "    #lc_df=pd.DataFrame( FILTRO_) #data frame de la curva real\n",
    "    lc_df=FILTRO_\n",
    "    lc_df.rename(columns={0:'mjd',1:'flux',2:'flux_err',\n",
    "                          3:'Upperlimit',4:'Instrument',5:'Telescope',6:'Source'},inplace=True)\n",
    "    lc_df['flux_err'].replace(0,0.05,inplace=True)\n",
    "\n",
    "    if len(lc_df.keys())>3:\n",
    "        lc_df=lc_df.loc[lc_df.loc[:, 'Upperlimit'] !='T'] #si ES T es upperlimit\n",
    "    #print('REAL DATA FRAME')\n",
    "    #print(lc_df)\n",
    "    DJ=lc_df['mjd']\n",
    "    if len(DJ)<1:\n",
    "        return print('No hay datos en la banda:',V)\n",
    "\n",
    "    if mag_to_flux==True:\n",
    "        lc_df['flux']=10**(-2*lc_df['flux']/5)\n",
    "        lc_df['flux_err']=(lc_df['flux_err']*lc_df['flux'])/1.086\n",
    "    flux=lc_df['flux']*mul\n",
    "    flux_err=lc_df['flux_err']*mul\n",
    "\n",
    "\n",
    "    if ot==True:\n",
    "        syn_df=pd.DataFrame( syntetic_df) #data frame de la curva real\n",
    "        syn_df.rename(columns={0:'mjd',1:'flux',2:'flux_err',\n",
    "                              3:'Upperlimit',4:'Instrument',5:'Telescope',6:'Source',7:'Ini',8:'Fin',9:'Alpha'},inplace=True)\n",
    "\n",
    "    if ot==False:\n",
    "        syn_df=pd.DataFrame( syntetic_df) #data frame de la curva real\n",
    "        syn_df.rename(columns={0:'mjd',1:'flux',2:'flux_err',\n",
    "                              3:'Upperlimit',4:'Instrument',5:'Telescope',6:'Source'},inplace=True)\n",
    "        if len(df_othersyn)>0:\n",
    "            df_othersyn=pd.DataFrame( df_othersyn) #data frame de la curva real\n",
    "            df_othersyn.rename(columns={0:'mjd',1:'flux',2:'flux_err',\n",
    "                              3:'Upperlimit',4:'Instrument',5:'Telescope',6:'Source'},inplace=True)\n",
    "\n",
    "\n",
    "    #print('SINTETIC DATA FRAME')\n",
    "    #print(syn_df)\n",
    "    #-------------------------------------------------------------------------------------------\n",
    "\n",
    "    import sys\n",
    "    #sys.path.append('C:/Users/equipo/Dropbox/ALR/src')\n",
    "    #sys.path.append('/data1/mauricio/ALR/src')\n",
    "    #sys.path.append(\"G:\\\\Mi unidad\\\\Work\\\\ALR\\src\")\n",
    "    #from ALR import Automated_Loess_Regression\n",
    "    #import plot_ALR\n",
    "\n",
    "    save_interactive='n'\n",
    "    alpha=0\n",
    "    nplot=0\n",
    "    while save_interactive=='n':\n",
    "        #GP(x,y,yerr,evaluar)\n",
    "        #return x_pred,y_pred,sigma\n",
    "        ALR = interpolate.interp1d(DJ, flux)\n",
    "        if min(DJ)<0 and max(DJ)>0:x_interp=np.arange(int(min(DJ)),int(max(DJ)+1)) # -> el +2 es para que calze con \"sampleo\"\n",
    "        if min(DJ)>0 and max(DJ)>0:x_interp=np.arange(int(min(DJ)),int(max(DJ)+1))\n",
    "        if min(DJ)<0 and max(DJ)<0:x_interp=np.arange(int(min(DJ)+1),int(max(DJ)))\n",
    "        if min(DJ)>0 and max(DJ)<0: print('Checkea los dias julianos')\n",
    "        #print(DJ)\n",
    "        #print(x_interp)\n",
    "        if len(x_interp)<2:\n",
    "            return print('No se puede hacer Loess con un Solo dato')\n",
    "        y_ALR=ALR(x_interp) #este es para el plot\n",
    "        y_err_ALR=np.sqrt(y_ALR)\n",
    "\n",
    "\n",
    "        x_df=syn_df.loc[syn_df.loc[:, 'mjd'] >=min(DJ)]\n",
    "        x_df=x_df.loc[x_df.loc[:, 'mjd'] <=max(DJ)]\n",
    "\n",
    "        #print(x_df['mjd'])\n",
    "        if len(x_df)==0:\n",
    "            return print('No hay espectros dentro del rango de curva de luz')\n",
    "        y_ALR2=ALR(x_df['mjd'])\n",
    "        y_err_ALR2=np.zeros(len(y_ALR2))\n",
    "        #este para calcular K y los residuales\n",
    "        #print('el loess',y_ALR2)\n",
    "        #fig=plot_ALR([ALR],invert_y_axis=False)\n",
    "        #plt.errorbar(x_interp,y_ALR,yerr=y_err_ALR,fmt='-')\n",
    "        #plt.plot(x_interp,y_ALR,'-')\n",
    "        #plt.plot(x_interp, y_ALR+3.0*y_err_ALR, '--', color='green'  , lw=1, zorder=1)\n",
    "        #plt.plot(x_interp, y_ALR-3.0*y_err_ALR, '--', color='green'  , lw=1, zorder=1)\n",
    "        #plt.show()\n",
    "\n",
    "        x_interp_df=pd.DataFrame(x_interp,columns=['mjd'])\n",
    "        y_ALR_df=pd.DataFrame(y_ALR,columns=['flux'])\n",
    "        y_err_ALR_df=pd.DataFrame(y_err_ALR,columns=['flux_err'])\n",
    "        x_interp_df.reset_index(drop=True,inplace=True)\n",
    "        ALR_df=pd.merge(x_interp_df, y_ALR_df, right_index=True, left_index=True)\n",
    "        ALR_df=pd.merge(ALR_df, y_err_ALR_df, right_index=True, left_index=True)\n",
    "\n",
    "        x_df=pd.DataFrame(x_df['mjd'],columns=['mjd'])\n",
    "        y_ALR2_df=pd.DataFrame(y_ALR2,columns=['flux'])\n",
    "        y_err_ALR2_df=pd.DataFrame(y_err_ALR2,columns=['flux_err'])\n",
    "        x_df.reset_index(drop=True,inplace=True)\n",
    "        #print(x_df)\n",
    "        #print(y_ALR2_df)\n",
    "        #print(y_err_ALR2_df)\n",
    "        ALR2_df=pd.merge(x_df, y_ALR2_df, right_index=True, left_index=True)\n",
    "        ALR2_df=pd.merge(ALR2_df, y_err_ALR2_df, right_index=True, left_index=True)\n",
    "\n",
    "\n",
    "        #DJ_band_df=pd.DataFrame(np.array(DJ_band),columns=['mjd']) #Estos son los espectros\n",
    "        #FLUX_band_df=pd.DataFrame(np.array(FLUX_band),columns=['flux'])\n",
    "        #syn_df=pd.merge(DJ_band_df, FLUX_band_df, right_index=True, left_index=True)\n",
    "        #print('ALR DATA FRAME')\n",
    "        #print(ALR2_df)\n",
    "\n",
    "        #print('MERGE DATA FRAME')\n",
    "        merge = pd.merge(syn_df, ALR2_df, how='inner', on=['mjd'])\n",
    "\n",
    "        #print('Syn df:',syn_df)\n",
    "        #print('Loess df (evualuated on syn):',ALR2_df)\n",
    "        #print('Merge df:',merge)\n",
    "\n",
    "        #print(DJ)\n",
    "        #print(DJ_band)\n",
    "        #print(merge['mjd'])\n",
    "        k=merge['flux_x']/merge['flux_y']\n",
    "        #------------------------------------------------------------------\n",
    "        if fig_title!='':\n",
    "            fig = plt.figure(figsize=(11,8))\n",
    "            fig.subplots_adjust(left=0.12, bottom=0.2, hspace=0.25, right=0.99, top=0.96)\n",
    "            ax_ = fig.add_subplot(211)\n",
    "\n",
    "            DJ_band=syn_df['mjd']\n",
    "            FLUX_band=syn_df['flux']\n",
    "            if len(df_othersyn)>0:\n",
    "                DJ_band_othersyn=df_othersyn['mjd']\n",
    "                FLUX_band_othersyn=df_othersyn['flux']\n",
    "\n",
    "            #ax_.errorbar(DJ,flux,yerr=flux_err,fmt='o',label='OBS',zorder=0,alpha=0.7)\n",
    "            if plot_syn==True:\n",
    "                ax_.plot(DJ_band,FLUX_band,'o',label='Synthetic',zorder=1,alpha=0.7)\n",
    "                if len(df_othersyn)>0:\n",
    "                    ax_.plot(DJ_band_othersyn,FLUX_band_othersyn,'o',label='other',zorder=5,alpha=0.7,color='k')\n",
    "\n",
    "                #ax_.plot(merge['mjd'],merge['flux_x']/k,'^',label='corrected',color='red',zorder=0)\n",
    "            ax_.plot(x_interp,y_ALR,'-',zorder=2,label='Interpolation')\n",
    "\n",
    "            ax_.plot(x_interp, y_ALR+y_err_ALR, '--', color='green'  , lw=1, zorder=2)\n",
    "            ax_.plot(x_interp, y_ALR-y_err_ALR, '--', color='green'  , lw=1, zorder=2)\n",
    "            plt.title('Filtro '+V)\n",
    "            plt.xlabel(r'$\\mathtt{MJD}$')\n",
    "            plt.ylabel(r'$\\mathtt{Flux}$')\n",
    "            if fig_title!='': plt.title('Filtro '+V+' '+fig_title)\n",
    "\n",
    "            ax_.tick_params('both', length=6, width=1, which='major', direction='in')\n",
    "            ax_.tick_params('both', length=3, width=1, which='minor', direction='in')\n",
    "            ax_.xaxis.set_ticks_position('both')\n",
    "            ax_.yaxis.set_ticks_position('both')\n",
    "            plt.legend()\n",
    "            plt.xlim(min(x_interp)-10,max(x_interp)+10)\n",
    "            #plt.rcParams['figure.figsize'] = [10, 8]\n",
    "            #plt.figure(999)\n",
    "        #--------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "        #fig = plt.figure(19085463,figsize=(9,9))\n",
    "        #fig.subplots_adjust(left=0.12, bottom=0.05, hspace=0.0, right=0.99, top=0.96)\n",
    "\n",
    "        residuales=(merge['flux_x']-merge['flux_y'])/merge['flux_y'] #sin-ALR\n",
    "\n",
    "        if fig_title!='':\n",
    "            ax  = fig.add_subplot(212)\n",
    "            ax.plot(merge['mjd'],np.zeros(len(merge['mjd'])),'--',ms=1,color='black')\n",
    "            ax.plot(merge['mjd'],residuales,'o',ms=10,color='red')\n",
    "            ax.tick_params('both', length=6, width=1, which='major', direction='in')\n",
    "            ax.tick_params('both', length=3, width=1, which='minor', direction='in')\n",
    "            ax.xaxis.set_ticks_position('both')\n",
    "            ax.yaxis.set_ticks_position('both')\n",
    "            ax.set_ylabel(r'$\\mathtt{Residuals = \\frac{F_{syn}-F_{ALR}}{F_{ALR}}}$')\n",
    "            ax.set_xlabel(r'$\\mathtt{MJD}$')\n",
    "            plt.xlim(min(x_interp)-10,max(x_interp)+10)\n",
    "            #plt.legend()\n",
    "\n",
    "\n",
    "        if len(plot_fases)>0:\n",
    "            for w in plot_fases:\n",
    "                ax_.axvline(w,ls='--',color='blue',alpha=0.5)\n",
    "                ax.axvline(w,ls='--',color='blue',alpha=0.5)\n",
    "        plt.show()\n",
    "\n",
    "        if interactive==True:\n",
    "            save_interactive=input('Save? y/n')\n",
    "            if save_interactive=='n':\n",
    "                alpha=float(input('Input the alpha value: '))\n",
    "            if save_interactive=='y':\n",
    "                continue\n",
    "            while save_interactive!='y' and save_interactive!='n':\n",
    "                print('Pls use y/n notation.')\n",
    "                save_interactive=input('Save? y/n')\n",
    "        if interactive==False:\n",
    "            save_interactive='y'\n",
    "    nplot=nplot+1\n",
    "\n",
    "    if ot==True:\n",
    "        if fig_title!='' and K==False:\n",
    "            return residuales,fig,merge['mjd'],merge['Ini'],merge['Fin'],merge['Alpha']\n",
    "        if K==True and fig_title!='' and get_ALR==False:\n",
    "            return residuales,fig,merge['mjd'],k,merge['Ini'],merge['Fin'],merge['Alpha']\n",
    "        if K==True and fig_title!='' and get_ALR==True:\n",
    "            return residuales,fig,merge['mjd'],k,merge['Ini'],merge['Fin'],merge['Alpha'],ALR_df\n",
    "        if fig_title=='' and K==True and get_ALR==True:\n",
    "            return residuales,merge['mjd'],k,merge['Ini'],merge['Fin'],merge['Alpha'],ALR_df\n",
    "        else:\n",
    "            return residuales\n",
    "    else:\n",
    "\n",
    "        if fig_title!='' and K==False:\n",
    "            return residuales,fig\n",
    "\n",
    "        elif K==True and fig_title!='' and get_ALR==False:\n",
    "            return residuales,fig,merge['mjd'],k\n",
    "\n",
    "        elif K==True and fig_title!='' and get_ALR==True:\n",
    "            return residuales,fig,merge['mjd'],k,ALR_df #este estoy entrando\n",
    "        elif K==True and fig_title=='' and get_ALR==True:\n",
    "            return residuales,merge['mjd'],k,ALR_df #este estoy entrando\n",
    "        else:\n",
    "            print('hola')\n",
    "            return residuales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SNTEDwRmMhhL"
   },
   "outputs": [],
   "source": [
    "def unir_filtros(FILTRO,filtros,jc_sloan=True):\n",
    "    filtro=filtros\n",
    "    FILTRO3=[]\n",
    "    filtros_convi2=[]\n",
    "    repetido=[]\n",
    "    filtros3=[]\n",
    "\n",
    "    if jc_sloan==True:\n",
    "\n",
    "            for j in range(20): #le pongo 20 para que revise 20 vees y saque todo\n",
    "                for i in filtro:\n",
    "                    if i!='B' and i!='V' and i!='R' and i!='I' and i!='U' and  i!='i' and i!='u'  and i!='g' and i!='r' and i!='z' and i!=\"u'\" and i!=\"g'\" and i!=\"r'\" and i!=\"i'\" and i!=\"z'\" :\n",
    "                        remove_filter(i,FILTRO,filtro)\n",
    "\n",
    "\n",
    "    for i in range(len(filtro)):\n",
    "        #print(filtro[i])\n",
    "\n",
    "        componentes=[]\n",
    "        componentes.append(i)\n",
    "        if filtro[i]  in repetido:\n",
    "            continue\n",
    "\n",
    "        for j in range(len(filtro)):\n",
    "                if filtro[i][:4]=='usno':\n",
    "                    if filtro[i]!=filtro[j] and filtro[i][5]== filtro[j][0] and filtro[j][:4]!='usno':\n",
    "                        componentes.append(j)\n",
    "                        repetido.append(filtro[j])\n",
    "                if filtro[i]!=filtro[j] and filtro[i][0]==filtro[j][0] and filtro[i][:4]!='usno' :\n",
    "                    componentes.append(j)\n",
    "                    repetido.append(filtro[j])\n",
    "        componentes=sorted(componentes)\n",
    "        FILTRO2=[]\n",
    "        for k in componentes:\n",
    "\n",
    "            FILTRO2=FILTRO[k]+FILTRO2\n",
    "\n",
    "        FILTRO3.append(sorted(FILTRO2))\n",
    "        filtros_convinados=[]\n",
    "        for qq in componentes:\n",
    "            filtros_convinados.append(filtro[qq])\n",
    "        filtros_convi2.append(filtros_convinados)\n",
    "\n",
    "\n",
    "        for jj in range(len(FILTRO2)):\n",
    "            DJ2=[]\n",
    "            flux2=[]\n",
    "            fluxerr2=[]\n",
    "            for ii in range(len(FILTRO2)):\n",
    "\n",
    "                DJ2.append(np.float(FILTRO2[ii][0]))\n",
    "                flux2.append(np.float(FILTRO2[ii][1]))\n",
    "\n",
    "            #necesitamos las barras de error\n",
    "                fluxerr2.append(np.float(FILTRO2[ii][2]))\n",
    "            xerr2=np.zeros(len(flux2)) #porque no hay error en X\n",
    "\n",
    "        fig=plt.figure(jj)\n",
    "        plt.errorbar(DJ2, flux2, fluxerr2,xerr2,'.','g')\n",
    "        plt.grid()\n",
    "        plt.xlabel('Dia Juliano')\n",
    "        plt.ylabel('FLUJO')\n",
    "        plt.gca().invert_yaxis()\n",
    "\n",
    "\n",
    "        plt.title('Curva de Luz filtro '+str(filtros_convinados))\n",
    "        plt.show()\n",
    "        #repetido.append(filtro[i])\n",
    "\n",
    "\n",
    "    for i in range(len(filtros_convi2)):\n",
    "        filtros3.append(filtros_convi2[i][0][0][0])\n",
    "\n",
    "\n",
    "    return FILTRO3,filtros3,filtros_convi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4zeU9XQXMhhM"
   },
   "outputs": [],
   "source": [
    "def Loess_fit(FILTRO_,V,mag_to_flux=False,interactive=False,fig_title='',use_cte='True',alpha=0,corte=40,plot=True): #entra solo una curva\n",
    "    cteB=6.460803024157998e-09\n",
    "    cteV=3.67558126207669e-09\n",
    "    cteR=2.2319872881446082e-09\n",
    "    cteI=1.1769629663231628e-09\n",
    "    cteU=4.346809582387867e-09\n",
    "\n",
    "    cteu=9.512689427618875e-09#859.5e-11\n",
    "    cteg=4.791168585588861e-09#466.9e-11\n",
    "    cter=2.818556152283821e-09#278.0e-11\n",
    "    ctei=1.9069984363571034e-09#185.2e-11\n",
    "    ctez=1.413365541656362e-09#131.5e-11\n",
    "    arr_ctes=['cteB','cteV','cteR','cteI','cteU','cteu','cteg','cter','ctei','ctez']\n",
    "    arr_val_ctes=[cteB,cteV,cteR,cteI,cteU,cteu,cteg,cter,ctei,ctez]\n",
    "    constante='cte'+V #pongo V pero es cualquier banda\n",
    "    print (constante)\n",
    "    for jj in range(len(arr_ctes)):\n",
    "            if constante==arr_ctes[jj]: #recorremos el arreglo de constantes en busca de la que le corresponde\n",
    "                print (constante,arr_ctes[jj],arr_val_ctes[jj])\n",
    "                mul=arr_val_ctes[jj]\n",
    "                if use_cte=='False':\n",
    "                    mul=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    lc_df=pd.DataFrame( FILTRO_) #data frame de la curva real\n",
    "    lc_df.rename(columns={0:'mjd',1:'flux',2:'flux_err',\n",
    "                          3:'Upperlimit',4:'Instrument',5:'Telescope',6:'Source'},inplace=True)\n",
    "    #lc_df['flux_err'].replace(0,0.05,inplace=True)\n",
    "\n",
    "    #if len(lc_df.keys())>3:\n",
    "     #   lc_df=lc_df.loc[lc_df.loc[:, 'Upperlimit'] !='T'] #si ES T es upperlimit, por lo que se elimina del df\n",
    "\n",
    "    DJ=lc_df['mjd']\n",
    "    if len(DJ)<5:\n",
    "        print('No hay suficientes datos (5) datos en la banda para realizar el fit:',V)\n",
    "        ALR_df=[]\n",
    "        return ALR_df\n",
    "\n",
    "    #return lc_df\n",
    "    if mag_to_flux==True:\n",
    "        lc_df['flux']=10**(-2*lc_df['flux']/5)\n",
    "        lc_df['flux_err']=(lc_df['flux_err']*lc_df['flux'])/1.086\n",
    "        lc_df['flux_err'].replace(0,0.05,inplace=True)\n",
    "    lc_df['flux_err'].replace(0,np.max(lc_df['flux'])*0.1,inplace=True)\n",
    "    flux=lc_df['flux']*mul\n",
    "    flux_err=lc_df['flux_err']*mul\n",
    "\n",
    "    import sys\n",
    "    sys.path.append('/home/mauri/Escritorio/ALR/src')\n",
    "    sys.path.append('/data1/mauricio/ALR/src')\n",
    "    sys.path.append(\"G:\\\\Mi unidad\\\\Work\\\\ALR\\src\")\n",
    "    from ALR import Automated_Loess_Regression\n",
    "    import plot_ALR\n",
    "\n",
    "    save_interactive='n'\n",
    "    \n",
    "    while save_interactive=='n':\n",
    "        if len(alpha)==1:\n",
    "\n",
    "            ALR = Automated_Loess_Regression(DJ, flux,err_y=flux_err,alpha=alpha[0])\n",
    "            if min(DJ)<0 and max(DJ)>0:x_interp=np.arange(int(min(DJ)),int(max(DJ)+1)) # -> el +2 es para que calze con \"sampleo\"\n",
    "            if min(DJ)>0 and max(DJ)>0:x_interp=np.arange(int(min(DJ)),int(max(DJ)+1))\n",
    "            if min(DJ)<0 and max(DJ)<0:x_interp=np.arange(int(min(DJ)+1),int(max(DJ)))\n",
    "            if min(DJ)>0 and max(DJ)<0: print('Checkea los dias julianos')\n",
    "            #print(DJ)\n",
    "            #print(x_interp)\n",
    "            if len(x_interp)<5:\n",
    "                return print('No se recomienda hacer Loess con menos de 5')\n",
    "            y_ALR,y_err_ALR=ALR.interp(x_interp) #este es para el plot\n",
    "\n",
    "            #print(x_df['mjd'])\n",
    "            #print('el loess',y_ALR2)\n",
    "\n",
    "            x_interp_df=pd.DataFrame(x_interp,columns=['mjd'])\n",
    "            y_ALR_df=pd.DataFrame(y_ALR,columns=['flux'])\n",
    "            y_err_ALR_df=pd.DataFrame(y_err_ALR,columns=['flux_err'])\n",
    "            x_interp_df.reset_index(drop=True,inplace=True)\n",
    "            ALR_df=pd.merge(x_interp_df, y_ALR_df, right_index=True, left_index=True)\n",
    "            ALR_df=pd.merge(ALR_df, y_err_ALR_df, right_index=True, left_index=True)\n",
    "\n",
    "\n",
    "            y_ALR2,y_err_ALR2=ALR.interp(DJ) #para los residuales\n",
    "        \n",
    "        if len(alpha)==2:\n",
    "            print('ENTRANDO AL DIVIDIDO')\n",
    "\n",
    "            #--------------\n",
    "            lc_df1=lc_df[:corte]\n",
    "            lc_df2=lc_df[corte:]\n",
    "            #------------\n",
    "            DJ1=lc_df1['mjd']\n",
    "            flux1=lc_df1['flux']\n",
    "            flux_err1=lc_df1['flux_err']\n",
    "            lc_upper_df1=lc_df1.loc[lc_df1.loc[:, 'Upperlimit'] =='T']\n",
    "            flux_upper1=lc_upper_df1['flux']\n",
    "            flux_err_upper1=lc_upper_df1['flux_err']\n",
    "            if len(DJ1)<5:\n",
    "                print('No hay suficientes datos (5) datos en la banda para realizar el fit:',V)\n",
    "                ALR_df=[]\n",
    "                return ALR_df\n",
    "                continue\n",
    "            \n",
    "            DJ2=lc_df2['mjd']\n",
    "            flux2=lc_df2['flux']\n",
    "            flux_err2=lc_df2['flux_err']\n",
    "            lc_upper_df2=lc_df2.loc[lc_df2.loc[:, 'Upperlimit'] =='T']\n",
    "            flux_upper2=lc_upper_df2['flux']\n",
    "            flux_err_upper2=lc_upper_df2['flux_err']\n",
    "            if len(DJ2)<5:\n",
    "                print('No hay suficientes datos (5) datos en la banda para realizar el fit:',V)\n",
    "                ALR_df=[]\n",
    "                return ALR_df\n",
    "                continue\n",
    "            \n",
    "            #-----------\n",
    "            ALR1=Automated_Loess_Regression(DJ1, flux1,err_y=flux_err1,alpha=alpha[0])\n",
    "            ALR2=Automated_Loess_Regression(DJ2, flux2,err_y=flux_err2,alpha=alpha[1])\n",
    "            \n",
    "            if min(DJ1)<0 and max(DJ1)>0:x_interp1=np.arange(int(min(DJ1)),int(max(DJ1)+1)) # -> el +2 es para que calze con \"sampleo\"\n",
    "            if min(DJ1)>0 and max(DJ1)>0:x_interp1=np.arange(int(min(DJ1)),int(max(DJ1)+1))\n",
    "            if min(DJ1)<0 and max(DJ1)<0:x_interp1=np.arange(int(min(DJ1)+1),int(max(DJ1)))\n",
    "            if min(DJ1)>0 and max(DJ1)<0: print('Checkea los dias julianos')\n",
    "                \n",
    "            if min(DJ2)<0 and max(DJ2)>0:x_interp2=np.arange(int(min(DJ2)),int(max(DJ2)+1)) # -> el +2 es para que calze con \"sampleo\"\n",
    "            if min(DJ2)>0 and max(DJ2)>0:x_interp2=np.arange(int(min(DJ2)),int(max(DJ2)+1))\n",
    "            if min(DJ2)<0 and max(DJ2)<0:x_interp2=np.arange(int(min(DJ2)+1),int(max(DJ2)))\n",
    "            if min(DJ2)>0 and max(DJ2)<0: print('Checkea los dias julianos')\n",
    "            #print('DJ:',DJ)\n",
    "            #print('flux;',flux)\n",
    "            #print('x para interpolar:',x_interp)\n",
    "            if len(x_interp1)<5:\n",
    "                print('No se recomienda hacer Loess con menos de 5')\n",
    "                continue\n",
    "            if len(x_interp2)<5:\n",
    "                print('No se recomienda hacer Loess con menos de 5')\n",
    "                continue\n",
    "            \n",
    "            y_ALR1,y_err_ALR1=ALR1.interp(x_interp1) #este es para el plot\n",
    "            y_ALR2,y_err_ALR2=ALR2.interp(x_interp2) #este es para el plot\n",
    "            y_ALR=np.concatenate((y_ALR1, y_ALR2), axis=None)\n",
    "            y_err_ALR=np.concatenate((y_err_ALR1, y_err_ALR2), axis=None)\n",
    "\n",
    "\n",
    "            #print(x_df['mjd'])\n",
    "            #print('el loess',y_ALR2)\n",
    "            \n",
    "            x_interp_df1=pd.DataFrame(x_interp1,columns=['mjd'])\n",
    "            x_interp_df2=pd.DataFrame(x_interp2,columns=['mjd'])\n",
    "            x_interp_df=pd.concat([x_interp_df1,x_interp_df2])\n",
    "            \n",
    "            y_ALR_df1=pd.DataFrame(y_ALR1,columns=['flux'])\n",
    "            y_ALR_df2=pd.DataFrame(y_ALR2,columns=['flux'])\n",
    "            y_ALR_df=pd.concat([y_ALR_df1,y_ALR_df2])\n",
    "\n",
    "            y_err_ALR_df1=pd.DataFrame(y_err_ALR1,columns=['flux_err'])\n",
    "            y_err_ALR_df2=pd.DataFrame(y_err_ALR2,columns=['flux_err'])\n",
    "            y_err_ALR_df=pd.concat([y_err_ALR_df1,y_err_ALR_df2])\n",
    "\n",
    "            \n",
    "            x_interp_df.reset_index(drop=True,inplace=True)\n",
    "            y_ALR_df.reset_index(drop=True,inplace=True)\n",
    "            y_err_ALR_df.reset_index(drop=True,inplace=True)\n",
    "            #print(y_ALR_df)\n",
    "            #print(x_interp_df)\n",
    "            #print(y_err_ALR_df)\n",
    "            ALR_df=pd.merge(x_interp_df, y_ALR_df, right_index=True, left_index=True)\n",
    "            #print(ALR_df)\n",
    "            ALR_df=pd.merge(ALR_df, y_err_ALR_df, right_index=True, left_index=True)\n",
    "            \n",
    "            ALR_df.drop_duplicates(subset=['mjd'],inplace=True)\n",
    "            #print(ALR_df)\n",
    "\n",
    "            y_ALR_residuals1,y_err_residuals1=ALR1.interp(DJ1) #para los residuales\n",
    "            y_ALR_residuals2,y_err_residuals2=ALR2.interp(DJ2[:]) #para los residuales\n",
    "            \n",
    "            y_ALR_residuals=np.concatenate((y_ALR_residuals1, y_ALR_residuals2), axis=None)\n",
    "\n",
    "        #------------------------------------------------------------------\n",
    "        if plot==True:\n",
    "            fig = plt.figure(1908546223,figsize=(6,8))\n",
    "            fig.subplots_adjust(left=0.12, bottom=0.05, hspace=0.1, right=0.99, top=0.96)\n",
    "            ax_ = fig.add_subplot(211)\n",
    "\n",
    "            ax_.errorbar(DJ,flux,yerr=flux_err,fmt='o',label='OBS',zorder=1)\n",
    "            ax_.plot(x_interp_df['mjd'],y_ALR,'-',label='Loess fit',zorder=2)\n",
    "            ax_.plot(x_interp_df['mjd'], y_ALR+3.0*y_err_ALR, '--', color='green'  , lw=1, zorder=1)\n",
    "            ax_.plot(x_interp_df['mjd'], y_ALR-3.0*y_err_ALR, '--', color='green'  , lw=1, zorder=1)\n",
    "            if mag_to_flux==False:\n",
    "                plt.gca().invert_yaxis()\n",
    "            plt.title('Filtro '+V)\n",
    "            plt.xlabel(r'$\\mathtt{Día}$')\n",
    "            plt.ylabel(r'$\\mathtt{Flux}$')\n",
    "            if fig_title!='': plt.title('Filtro '+V+' '+fig_title)\n",
    "\n",
    "            ax_.tick_params('both', length=6, width=1, which='major', direction='in')\n",
    "            ax_.tick_params('both', length=3, width=1, which='minor', direction='in')\n",
    "            ax_.xaxis.set_ticks_position('both')\n",
    "            ax_.yaxis.set_ticks_position('both')\n",
    "            plt.legend()\n",
    "            #plt.xlim(min(DJ_band)-3,max(DJ_band)+3)\n",
    "            #plt.rcParams['figure.figsize'] = [10, 8]\n",
    "            #plt.figure(999)\n",
    "            #--------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "            #fig = plt.figure(19085463,figsize=(9,9))\n",
    "            #fig.subplots_adjust(left=0.12, bottom=0.05, hspace=0.0, right=0.99, top=0.96)\n",
    "            ax  = fig.add_subplot(212)\n",
    "\n",
    "            if len(alpha)==1:\n",
    "                residuales=((flux-y_ALR2)/flux) #real-loess\n",
    "            if len(alpha)==2:\n",
    "                residuales=((flux-y_ALR_residuals)/flux) #real-loess\n",
    "\n",
    "                \n",
    "\n",
    "            ax.plot(DJ,np.zeros(len(DJ)),'--',ms=1,color='black')\n",
    "            ax.plot(DJ,residuales,'o',ms=10,color='red')\n",
    "            ax.tick_params('both', length=6, width=1, which='major', direction='in')\n",
    "            ax.tick_params('both', length=3, width=1, which='minor', direction='in')\n",
    "            ax.xaxis.set_ticks_position('both')\n",
    "            ax.yaxis.set_ticks_position('both')\n",
    "            ax.set_ylabel(r'$\\mathtt{Residuals = \\frac{F_{syn}-F_{ALR}}{F_{ALR}}}$')\n",
    "            ax.set_xlabel(r'$\\mathtt{MJD}$')\n",
    "            #plt.xlim(min(DJ_band)-3,max(DJ_band)+3)\n",
    "            #plt.legend()\n",
    "\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "        if len(alpha)==1:\n",
    "            print ('The alpha value for the ALR is:',ALR.alpha)\n",
    "        if len(alpha)==2:\n",
    "            print ('The alpha values for the ALR is:',ALR1.alpha,'and',ALR2.alpha)\n",
    "\n",
    "\n",
    "        if interactive==True:\n",
    "            save_interactive=input('Save? y/n')\n",
    "            if save_interactive=='n':\n",
    "                alpha=float(input('Input the alpha value: '))\n",
    "            if save_interactive=='y':\n",
    "                continue\n",
    "            while save_interactive!='y' and save_interactive!='n':\n",
    "                print('Pls use y/n notation.')\n",
    "                save_interactive=input('Save? y/n')\n",
    "        if interactive==False:\n",
    "            save_interactive='y'\n",
    "\n",
    "\n",
    "    return ALR_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fDoS74A-MhhO"
   },
   "outputs": [],
   "source": [
    "def calibrar_spectra(ESPECTRO,pos,banda,fases,FILTRO,filtros,return_k=False,tipo='',use_cte=True,mag_to_flux=True,move_lc=0,system='windows'):\n",
    "\n",
    "    if system=='windows':\n",
    "        response_df=pd.read_csv('G:/Mi unidad/Work/Universidad/Phd/Practica2/Splines_eachfilter/spline_'+banda[0]+'.txt',sep='\\s+',comment='#',header=None)\n",
    "    if system=='ubuntu':\n",
    "        response_df=pd.read_csv('/data1/mauricio/Dropbox/Universidad/Phd/Practica2/Splines_eachfilter/spline_'+banda[0]+'.txt',sep='\\s+',comment='#',header=None)\n",
    "\n",
    "    response_df.columns=['wave','response']\n",
    "\n",
    "\n",
    "    #plt.plot(response_df['wave'],response_df['response'],'--')\n",
    "    #plt.show()\n",
    "\n",
    "    #Ahora calculamos la fotometria sintetica y tambien ploteamos el espectro con el porcentaje de la banda para claridad\n",
    "\n",
    "    #%run /home/mauri/Escritorio/Universidad/Codes/Funciones.ipynb\n",
    "\n",
    "    spec1_df=ESPECTRO[pos]\n",
    "    spec1_df.columns=['wave','flux']\n",
    "    spec1_df\n",
    "    spec1_df.sort_values('wave',ignore_index=True,inplace=True)\n",
    "\n",
    "    #regrillamos la respuesta de la banda response_df a la de spec1_df\n",
    "\n",
    "    import scipy\n",
    "    from scipy.interpolate import griddata\n",
    "    regrid=griddata(response_df['wave'], response_df['response'], spec1_df['wave'], method='linear', rescale=False)\n",
    "    df_regrid=pd.DataFrame({'wave':spec1_df['wave'],'response':regrid})\n",
    "    df_regrid = df_regrid.dropna(how='any') #eliminamos los nan\n",
    "\n",
    "\n",
    "    merge = pd.merge(spec1_df, df_regrid, how='inner', on=['wave'])\n",
    "\n",
    "    #if porcentaje==1:\n",
    "\n",
    "\n",
    "    syn=Syntetic_photometry_v2(spec1_df['wave'],spec1_df['flux'],response_df['wave'],response_df['response'])\n",
    "    print('syn|percentage')\n",
    "    print(syn)\n",
    "\n",
    "\n",
    "    #Solo para visualizar como cubre la banda\n",
    "    plt.plot(df_regrid['wave'],df_regrid['response'],'-')\n",
    "    plt.plot(spec1_df['wave'],spec1_df['flux']/np.max(spec1_df['flux']))\n",
    "    plt.title(fases[pos])\n",
    "    plt.show()\n",
    "    if float(syn[1])<0.7:\n",
    "        print('No cubre lo suficiente la banda')\n",
    "        return spec1_df,syn[1]\n",
    "\n",
    "    #ahora que tenemos la sintetica vamos a calcular la fotometria obs para el dia del espectro\n",
    "    ##path_lc='/media/mauri/62882B44882B15D7/Universidad/Phd/Practica2/Photometry_unidas2/'+tipo+'/'+name+'_photometry.dat'\n",
    "    ##if tipo=='Ia':\n",
    "    ##    path_lc='/media/mauri/62882B44882B15D7/Universidad/Phd/Practica2/Photometry_loess/Ia/'+name+'_photometry.dat'\n",
    "    ##if tipo=='II':\n",
    "    ##    if system=='windows':\n",
    "    ##        path_lc='G:/Mi unidad/Work/Universidad/Phd/Practica2/Photometry_unidas2/'+tipo+'_loess_unidas/'+name+'_photometry.dat'\n",
    "    ##    if system=='ubuntu':\n",
    "    ##        path_lc='/data1/mauricio/Dropbox/Universidad/Phd/Practica2/Photometry_unidas2/'+tipo+'_loess_unidas/'+name+'_photometry.dat'\n",
    "##\n",
    " #   #if Ibc==True:\n",
    "     #   path_lc='/media/mauri/62882B44882B15D7/Universidad/Phd/Practica2/SNdata_oldpractice/Supernovas_def/Photometry_original/'+tipo+'/'+name+'_photometry.dat'\n",
    "\n",
    "\n",
    "    #\"FILTRO,filtros=data_curvas(path_lc)\n",
    "    print(filtros)\n",
    "\n",
    "\n",
    "    index_lc=filtros.index(banda[0])\n",
    "    syn_df=pd.DataFrame({'mjd':fases[pos]+move_lc,'flux':syn[0]},index=[0],dtype='float64')\n",
    "    #FILTRO_=pd.DataFrame(FILTRO[index_lc],dtype='float64')\n",
    "    FILTRO_=FILTRO[index_lc]\n",
    "    #plt.plot(FILTRO_[0],FILTRO_[1])\n",
    "    #plt.title('Curva '+ filtros[index_lc])\n",
    "    #plt.gca().invert_yaxis()\n",
    "    #plt.show()\n",
    "\n",
    "    residuales,fig,merge_2,k=sin_vs_obs(syn_df,banda[0],FILTRO_,mag_to_flux=mag_to_flux,K=True,fig_title='Comparacion',\n",
    "                                       use_cte=use_cte)\n",
    "\n",
    "\n",
    "    #calculamos con el la sintetica dividiendo por el valor de k\n",
    "    syn2=Syntetic_photometry_v2(spec1_df['wave'],spec1_df['flux']/float(k),response_df['wave'],response_df['response'])\n",
    "    syn2_df=pd.DataFrame({'mjd':fases[pos]+move_lc,'flux':syn2[0]},index=[0],dtype='float64')\n",
    "    print('syn|percentage')\n",
    "    print(syn2)\n",
    "    residuales,fig,merge_2,k2=sin_vs_obs(syn2_df,banda[0],FILTRO_,mag_to_flux=mag_to_flux,K=True,fig_title='Comparacion',\n",
    "                                        use_cte=use_cte)\n",
    "\n",
    "    #ahora que sabemos que el valor de k funciona, procedemos a correguir el espectro\n",
    "    spectro_df_corr=ESPECTRO[pos].copy()\n",
    "    spectro_df_corr['flux']=spectro_df_corr['flux']/float(k)\n",
    "\n",
    "    plt.plot(spectro_df_corr['wave'],spectro_df_corr['flux'])\n",
    "    plt.title(fases[pos])\n",
    "    plt.show()\n",
    "    if return_k==True:\n",
    "        return spectro_df_corr,syn[1],k\n",
    "    return spectro_df_corr,syn[1]#el espectro corregido y el porcentaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WthwT9FHMhhQ"
   },
   "outputs": [],
   "source": [
    "def prom_spec(lista_ESPEC,porcentajes):\n",
    "    #recibe la lista con los dataframe de los espectros a promediar\n",
    "    #retorna el dataframe promediado\n",
    "\n",
    "    #hacemos una lista con los espectros a promediar:\n",
    "    #lo mas facil es regrillar a 1 amstrong y ver donde se solapan los espectros\n",
    "    porcentajes=np.array(porcentajes)\n",
    "    lista_ESPEC_1A=[]\n",
    "    for i in range(len(lista_ESPEC)):\n",
    "        wave=lista_ESPEC[i]['wave']\n",
    "        flux=lista_ESPEC[i]['flux']\n",
    "        from scipy import interpolate\n",
    "        cs = interpolate.interp1d(wave, flux,fill_value = \"extrapolate\")\n",
    "        #cs = CubicSpline(WAVE_SPEC, FLUX_SPEC)\n",
    "        xnew=np.arange(min(wave),max(wave)+1,1)\n",
    "        diferencia=(xnew[0]-int(xnew[0]))\n",
    "\n",
    "        xnew=xnew-diferencia\n",
    "        ynew=cs(xnew)\n",
    "        df_1A=pd.DataFrame({'wave':xnew,'flux':ynew})\n",
    "        lista_ESPEC_1A.append(df_1A)\n",
    "\n",
    "        #plt.plot(xnew,ynew)\n",
    "\n",
    "\n",
    "    for j in range(len(lista_ESPEC_1A)-1):\n",
    "        if j==0:\n",
    "            a=lista_ESPEC_1A[j].merge(lista_ESPEC_1A[j+1],how='outer',on=['wave'])\n",
    "        else:\n",
    "            a=a.merge(lista_ESPEC_1A[j+1],how='outer',on=['wave'])\n",
    "\n",
    "    a['flux_y'].fillna(a['flux_x'], inplace=True)\n",
    "    a['flux_x'].fillna(a['flux_y'], inplace=True) #donde dicen nan, copias el valor del otro spectro\n",
    "\n",
    "\n",
    "    a['mean']=a.drop('wave',axis='columns').mean(axis=1)\n",
    "\n",
    "    if len(porcentajes)==2:\n",
    "        a['mean_W']=np.average([a['flux_x'],a['flux_y']],axis=0,weights=porcentajes)\n",
    "\n",
    "    prom=pd.DataFrame({'wave':a['wave'],'flux':a['mean']})\n",
    "\n",
    "    prom.sort_values('wave',ignore_index=True,inplace=True)\n",
    "\n",
    "\n",
    "    return prom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w3-di2RPMhhQ"
   },
   "outputs": [],
   "source": [
    "def ordenar_bandas(FILTRO,filtros):\n",
    "    def orden_value(filtro):\n",
    "        if filtro=='U':\n",
    "            return 0\n",
    "        if filtro=='B':\n",
    "            return 1\n",
    "        if filtro=='V':\n",
    "            return 2\n",
    "        if filtro=='R':\n",
    "            return 3\n",
    "        if filtro=='I':\n",
    "            return 4\n",
    "        if filtro=='u':\n",
    "            return 5\n",
    "        if filtro=='g':\n",
    "            return 6\n",
    "        if filtro=='r':\n",
    "            return 7\n",
    "        if filtro=='i':\n",
    "            return 8\n",
    "        if filtro=='z':\n",
    "            return 9\n",
    "\n",
    "    orden=['U','B','V','R','I','u','g','r','i','z']\n",
    "\n",
    "    parejas_viejas=[]\n",
    "    parejas_nuevas=[]\n",
    "\n",
    "    for i in range(len(filtros)):\n",
    "           parejas_viejas.append([filtros[i],i])\n",
    "\n",
    "    #las ordenasmos\n",
    "    filtros.sort(key=orden_value)\n",
    "\n",
    "    for i in range(len(filtros)):\n",
    "           parejas_nuevas.append([filtros[i],i])\n",
    "\n",
    "    new_orden_FILTRO=list(np.zeros(len(filtros))) #creo lista vacia para rellenar con nuevo orden\n",
    "\n",
    "    for j in range(len(parejas_viejas)):\n",
    "        banda=parejas_viejas[j][0]\n",
    "        old_index=parejas_viejas[j][1]\n",
    "        for k in range(len(parejas_nuevas)):\n",
    "            if banda==parejas_nuevas[k][0]:\n",
    "                new_index=parejas_nuevas[k][1]\n",
    "                #print('El nuevo indice de ',banda, 'es',new_index,'el viejo es',old_index)\n",
    "                new_orden_FILTRO[new_index]=FILTRO[old_index]\n",
    "\n",
    "    return new_orden_FILTRO,filtros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximo_lc(tipo,sn,ubuntu=False):\n",
    "    if tipo=='II':\n",
    "        if ubuntu==True:\n",
    "            maximum_df=pd.read_csv(\"/mnt/g/Mi unidad/Work/OT_unidos_2/OT_combines_test/maximum_II.txt\")\n",
    "\n",
    "        else:\n",
    "            maximum_df=pd.read_csv(\"G:\\Mi unidad\\Work\\OT_unidos_2\\OT_combines_test\\maximum_II.txt\")\n",
    "        max_=float(maximum_df.loc[maximum_df['name']==sn]['fase'])\n",
    "        return max_\n",
    "    if tipo=='Ia':\n",
    "        if ubuntu==True:\n",
    "             \n",
    "            df_max=pd.read_csv(\"/mnt/g/Mi unidad/Work/OT_unidos_2/OT_combines_test/maximum_Ia.txt\")\n",
    "        else:\n",
    "            df_max=pd.read_csv(\"G:\\Mi unidad\\Work\\OT_unidos_2\\OT_combines_test\\maximum_Ia.txt\")\n",
    "        df_max[df_max.name==sn]\n",
    "\n",
    "    if tipo=='Ibc' or tipo=='Ib' or tipo=='Ic':\n",
    "            df_max=pd.read_csv(r\"G:\\Mi unidad\\Work\\Universidad\\Phd\\Practica2\\maximum_Ibc.dat\")\n",
    "            #df_max=pd.read_csv( \"G:\\Mi unidad\\Spectral Time Series - Ramirez M\\Data\\maximum_perband.dat\")\n",
    "            df_max[df_max.name==sn]\n",
    "    \n",
    "    band_system=['V','R','r','g','i','I','B','U','u','z'] #We use this order to obtain the day of the maximum\n",
    "    for elemento in band_system:\n",
    "\n",
    "        maximum=df_max.loc[(df_max['name']==sn) & (df_max['filter']==elemento )]['mjd_max']\n",
    "        if len(maximum)>0:\n",
    "            maximum=float(maximum)\n",
    "            break\n",
    "    return maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redden_spectrum_adjusted(la, spec, Rv, ebmv, norm='n'):\n",
    "    \"\"\"\n",
    "    Version en python de codigo en IDL de G. Pignata 2004\n",
    "\n",
    "    Aplica corrección de enrojecimiento o desenrojecimiento a un espectro dado,\n",
    "    basándose en la ley de Cardelli. La función también ofrece la opción de normalizar\n",
    "    el espectro corregido.\n",
    "\n",
    "    Parámetros:\n",
    "    la (array de numpy): Array de longitudes de onda en Ångströms.\n",
    "    spec (array de numpy): Espectro original que se desea corregir.\n",
    "    Rv (float): Relación de extinción total a selectiva (R_V).\n",
    "    ebmv (float): Exceso de color E(B-V). Valores positivos para enrojecimiento,\n",
    "                  negativos para desenrojecimiento.\n",
    "    norm (str): 'y' para normalizar el espectro corregido, cualquier otro valor\n",
    "                para no normalizar.\n",
    "\n",
    "    Devuelve:\n",
    "    array de numpy: Espectro corregido.\n",
    "\n",
    "    Notas:\n",
    "    - La corrección se aplica solo para longitudes de onda entre 3030 Å y 33000 Å.\n",
    "    - Utiliza la ley de Cardelli para calcular la extinción.\n",
    "    \"\"\"\n",
    "\n",
    "    # Verifica si hay longitudes de onda menores a 3030 Å, que no son válidas\n",
    "    if np.min(la) <= 1250:\n",
    "        raise ValueError(\"No hay corrección para longitudes de onda menores de 1250\")\n",
    "\n",
    "    # Inicializa abs_flux como un arreglo de unos, del mismo tamaño que spec\n",
    "    abs_flux = np.ones_like(spec)\n",
    "\n",
    "    # Corrección en el infrarrojo (IR)\n",
    "    la_ir_indices = np.where((la < 33000) & (la > 9000))[0]\n",
    "    if len(la_ir_indices) > 0:\n",
    "        # Calcula y aplica la corrección IR a las partes relevantes de abs_flux\n",
    "        la_ir = la[la_ir_indices]\n",
    "        x_ir = 1.0 / (la_ir / 10000.0)\n",
    "        a_ir = 0.574 * x_ir ** 1.61\n",
    "        b_ir = -0.527 * x_ir ** 1.61\n",
    "        abs_flux[la_ir_indices] = 10 ** (-0.4 * ((a_ir * Rv + b_ir) * ebmv))\n",
    "\n",
    "    # Corrección óptica\n",
    "    la_opt_indices = np.where((la <= 9000) & (la > 3000))[0]\n",
    "    if len(la_opt_indices) > 0:\n",
    "        # Calcula y aplica la corrección óptica\n",
    "        la_opt = la[la_opt_indices]\n",
    "        x_opt = 1.0 / (la_opt / 10000.0)\n",
    "        y = x_opt - 1.82\n",
    "        a_opt = 1.0 + 0.17699*y - 0.50447*y**2 - 0.02427*y**3 + 0.72085*y**4 + 0.01979*y**5 - 0.77530*y**6 + 0.32999*y**7\n",
    "        b_opt = 1.41338*y + 2.28305*y**2 + 1.07233*y**3 - 5.38434*y**4 - 0.62251*y**5 + 5.30260*y**6 - 2.09002*y**7\n",
    "        abs_flux[la_opt_indices] = 10 ** (-0.4 * ((a_opt * Rv + b_opt) * ebmv))\n",
    "        \n",
    "    # Corrección UV\n",
    "    la_uv_indices = np.where((la <= 3000) & (la >= 1250))[0]\n",
    "    if len(la_uv_indices) > 0:\n",
    "        la_uv = la[la_uv_indices]\n",
    "        x_uv = 1.0 / (la_uv / 10000.0)  # Convertir a micrómetros y luego tomar el inverso\n",
    "\n",
    "        # Calcula Fa(x) y Fb(x)\n",
    "        Fa = np.where((x_uv > 5.9) & (x_uv < 8), -0.04473 * (x_uv - 5.9)**2 - 0.009779 * (x_uv - 5.9)**3, 0)\n",
    "        Fb = np.where((x_uv > 5.9) & (x_uv < 8), 0.2130 * (x_uv - 5.9)**2 + 0.1207 * (x_uv - 5.9)**3, 0)\n",
    "\n",
    "        # Calcula a(x) y b(x)\n",
    "        a_uv = 1.752 - 0.316 * x_uv - 0.104 / ((x_uv - 4.67)**2 + 0.341) + Fa\n",
    "        b_uv = -3.090 + 1.825 * x_uv + 1.206 / ((x_uv - 4.62)**2 + 0.263) + Fb\n",
    "\n",
    "        # Aplica la corrección UV\n",
    "        abs_flux[la_uv_indices] = 10 ** (-0.4 * ((a_uv * Rv + b_uv) * ebmv))\n",
    "        \n",
    "\n",
    "    # Normaliza abs_flux si se requiere\n",
    "    if norm == 'y':\n",
    "        abs_flux /= np.mean(abs_flux) if np.mean(abs_flux) > 0 else -np.mean(abs_flux)\n",
    "\n",
    "    # Calcula el espectro de salida multiplicando el espectro original por abs_flux\n",
    "    spec_out = spec * abs_flux\n",
    "    return spec_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_spetra(ESPECTRO,fases,path,err=False):\n",
    "    #ahora escribimos el espectro promediado\n",
    "    file1=open(path,'w')\n",
    "    \n",
    "    for j in range(len(fases)):\n",
    "\n",
    "        file1.write('# time:\\t'+str(fases[j])+'\\n')\n",
    "        file1.write('# SPEC \\n')\n",
    "        file1.write('#      WAVE   FLUX')\n",
    "        df_spec=ESPECTRO[j]\n",
    "        for ii in range(len(df_spec)):\n",
    "            file1.write('\\n')\n",
    "            if err==True:\n",
    "                file1.write(str(df_spec.iloc[ii]['wave'])+'\\t'+str(float(df_spec.iloc[ii]['flux']))+'\\t'+str(float(df_spec.iloc[ii]['fluxerr'])))\n",
    "            else:\n",
    "                file1.write(str(df_spec.iloc[ii]['wave'])+'\\t'+str(float(df_spec.iloc[ii]['flux'])))\n",
    "        file1.write('\\n')\n",
    "    file1.close()\n",
    "\n",
    "def escribir_curvas_luz(FILTRO, filtros, file_path, sn_name):\n",
    "    \"\"\"\n",
    "    Escribe un archivo de curva de luz en el formato especificado, utilizando los datos de una lista de DataFrames y filtros.\n",
    "\n",
    "    :param FILTRO: Lista de DataFrames, donde cada DataFrame contiene las columnas de datos para un filtro.\n",
    "    :param filtros: Lista de nombres de filtros correspondientes a los DataFrames en FILTRO.\n",
    "    :param file_path: Ruta del archivo a escribir.\n",
    "    :param sn_name: Nombre de la supernova que se incluirá en el encabezado.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        # Escribir encabezado\n",
    "        file.write(\"###################### HEADER ######################\\n\")\n",
    "        file.write(f\"# SNNAME:\\t{sn_name}\\n\")\n",
    "        file.write(\"###################### HEADER ######################\\n\")\n",
    "        \n",
    "        # Iterar sobre cada filtro y su DataFrame correspondiente\n",
    "        for i, filtro_df in enumerate(FILTRO):\n",
    "            file.write(\"\\n\\n\")\n",
    "            file.write(f\"# FILTER {filtros[i]}\\n\")\n",
    "            file.write(\"#        MJD  MAG  MAGERR  Upperlimit  Instrument  Telescope  Source\")\n",
    "            for _, row in filtro_df.iterrows():\n",
    "                file.write(f\"\\n\\t{row[0]:.3f}\\t{row[1]:.3f}\\t{row[2]:.3e}\\tF\\tnan\\tnan\\tnan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lc(ESPECTRO,fases,filtros,name='',path2=None,z=0,do_plot=False,use_cte=True,ubuntu=False):\n",
    "\n",
    "    cteB=6.460803024157998e-09\n",
    "    cteV=3.67558126207669e-09\n",
    "    cteR=2.2319872881446082e-09\n",
    "    cteI=1.1769629663231628e-09\n",
    "    cteU=4.346809582387867e-09\n",
    "\n",
    "    cteu=9.512689427618875e-09#859.5e-11\n",
    "    cteg=4.791168585588861e-09#466.9e-11\n",
    "    cter=2.818556152283821e-09#278.0e-11\n",
    "    ctei=1.9069984363571034e-09#185.2e-11\n",
    "    ctez=1.413365541656362e-09#131.5e-11\n",
    "    print(\"Tienes curvas de luz en los fitros:\\n\",filtros)\n",
    "    bandas=[]\n",
    "    if ubuntu==True:\n",
    "        lista=os.listdir(r\"/mnt/g/Mi unidad/Work/Universidad/Phd/Practica2/Splines_eachfilter_2\")\n",
    "    else:\n",
    "        lista=os.listdir(r\"G:\\Mi unidad\\Work\\Universidad\\Phd\\Practica2\\Splines_eachfilter_2\")\n",
    "    nombres_archivos_response= {\n",
    "    \"U\": \"spline_U.txt\",\n",
    "    \"B\": \"spline_B.txt\",\n",
    "    \"V\": \"spline_V.txt\",   \n",
    "    \"R\": \"bessell_R_ph_lines.dat\",#We use this because have the telluric lines\n",
    "    \"I\": \"bessell_I_ph_lines.dat\",#We use this because have the telluric lines\n",
    "    \"u\": \"spline_u'.txt\",\n",
    "    \"g\": \"spline_g'.txt\",\n",
    "    \"r\": \"spline_r'.txt\", #this already have the telluric line\n",
    "    \"i\": \"spline_i'.txt\", #this already have the telluric lines\n",
    "    \"z\": \"spline_z'.txt\", \n",
    "    }\n",
    "    bandas_con_curvas=[]\n",
    "    for filtro in filtros:\n",
    "        bandas_con_curvas.append(nombres_archivos_response[filtro])\n",
    "\n",
    "    print('We are going to comptue syn photometry on bands:\\n')\n",
    "\n",
    "    print(bandas_con_curvas)\n",
    "    \n",
    "\n",
    "    ######## guardamos los datos de las bandas con curvas en  datos_bandasspline  \n",
    "\n",
    "    datos_bandasspline=[] #los spline que ocuparemos que tienen curvas\n",
    "\n",
    "\n",
    "    response_list=[]\n",
    "    for i in range(len(bandas_con_curvas)):\n",
    "        #with open (os.path.join(os.getcwd(),\"Data\",\"Splines_eachfilter\",str(bandas_con_curvas[i])),'r') as f:     \n",
    "        if ubuntu==True:\n",
    "            file_path=os.path.join(r\"/mnt/g/Mi unidad/Work/Universidad/Phd/Practica2\",\"Splines_eachfilter_2\",str(bandas_con_curvas[i]))\n",
    "        else:\n",
    "            file_path=os.path.join(r\"G:Mi unidad\\Work\\Universidad\\Phd\\Practica2\",\"Splines_eachfilter_2\",str(bandas_con_curvas[i]))\n",
    "        df_response=pd.read_csv(file_path,sep='\\s+',comment='#',header=None)\n",
    "        df_response.columns=['wave','response']\n",
    "        #plt.plot(df_response.wave,df_response.response)\n",
    "        #plt.show()\n",
    "        response_list.append(df_response)\n",
    "    \n",
    "    \n",
    "    datos_espectros_spline=ESPECTRO\n",
    "    \n",
    "    SINTETICA=[]\n",
    "\n",
    "    if path2 is not None:\n",
    "        # Create output directories\n",
    "        try:    \n",
    "            os.mkdir(path2)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        \n",
    "        ##############write####################################################\n",
    "        file=open(os.path.join(path2,name+\"_synphotometry.dat\"),\"w\")\n",
    "        file.write(\"###################### HEADER ######################\\n\")\n",
    "        file.write(\"# SNNAME:\\t\"+ name+\"\\n\")\n",
    "        file.write(\"###################### HEADER ######################\\n\")\n",
    "\n",
    "    LC_list=[]\n",
    "    \n",
    "    for q in range(len(response_list)):\n",
    "\n",
    "            response_df=response_list[q]\n",
    "\n",
    "\n",
    "            cont=0\n",
    "            le=[]\n",
    "            la=[]\n",
    "            for i in range(len(ESPECTRO)):\n",
    "                \n",
    "                spec1_df=ESPECTRO[i]\n",
    "                spec1_df=spec1_df.clip(0) #para que no hayan valores negativos\n",
    "                #spec1_df.columns=[\"wave\",\"flux\"]\n",
    "                #spec1_df\n",
    "                spec1_df.sort_values(\"wave\",ignore_index=True,inplace=True)\n",
    "\n",
    "\n",
    "                #plt.figure(i)    \n",
    "                #plt.plot(response_df[\"wave\"],response_df[\"response\"],\"-\")\n",
    "                #plt.plot(spec1_df[\"wave_z\"],spec1_df[\"flux\"]/np.max(spec1_df[\"flux\"]))\n",
    "                #plt.title(\"SPECTRO Y RESPUESTA\")\n",
    "                #plt.show()\n",
    "                    \n",
    "                #spec1_df['photons']=convert_to_photons(np.array(spec1_df[\"flux_z\"]), np.arraY(spec1_df[\"wave_z\"]))\n",
    "                #print(spec1_df)\n",
    "                syn,porcentaje=Syntetic_photometry_v2(spec1_df[\"wave\"],spec1_df[\"flux\"],response_df[\"wave\"],response_df[\"response\"])\n",
    "                #print(syn)\n",
    "                #print('el porcentaje es', porcentaje)\n",
    "\n",
    "                #merge = pd.merge(spec1_df, response_df, how=\"inner\", on=[\"wave\"])\n",
    "                #print(merge)\n",
    "                \n",
    "                \n",
    "                #pasamos a mag\n",
    "                arr_ctes=['cteB','cteV','cteR','cteI','cteU','cteu','cteg','cter','ctei','ctez']\n",
    "                arr_val_ctes=[cteB,cteV,cteR,cteI,cteU,cteu,cteg,cter,ctei,ctez]\n",
    "                V=filtros[q]\n",
    "                constante='cte'+V #pongo V pero es cualquier banda\n",
    "                #print (constante)\n",
    "                for jj in range(len(arr_ctes)): \n",
    "                    if constante==arr_ctes[jj]: #recorremos el arreglo de constantes en busca de la que le corresponde\n",
    "                        #print (constante,arr_ctes[jj],arr_val_ctes[jj])\n",
    "                        mul=arr_val_ctes[jj]\n",
    "                if use_cte==False:\n",
    "                    mul=1\n",
    "                mag=-2.5*np.log10(syn/mul)\n",
    "                #syn=syn#/mul\n",
    "                syn=mag\n",
    "                #porcentaje=len(merge[\"wave\"])/len(response_df)\n",
    "                \n",
    "                \n",
    "                #print(\"ESTE ES EL SYN Y EL PORCENTAJE\",syn,porcentaje)\n",
    "                if porcentaje*100>=95:\n",
    "                    if path2 is not None:\n",
    "                        if cont==0:\n",
    "                            file.write(\"\\n\")  \n",
    "                            file.write(\"# FILTER \"+str(filtros[q])+\"\\n\")\n",
    "                            file.write(\"#        MJD  MAG  MAGERR  Upperlimit  Instrument  Telescope  Source\\n\")\n",
    "                        \n",
    "                        \n",
    "                    #syn=Syntetic_photometry_same_length(merge[\"wave\"],merge[\"flux\"],merge[\"wave\"],merge[\"response\"])\n",
    "                    #print(\"el porcentaje de la banda:\",porcentaje)\n",
    "                    #plt.figure(1000000)\n",
    "                    la.append(fases[i])\n",
    "                    le.append(syn)\n",
    "                ##plt.plot(fases[i],syn,\"o\")\n",
    "                #print (\"EL PORCENTAJE DE LA BANDA \"+str(bandas_con_curvas[q]) +\" ES DE :\",porcentaje*100)\n",
    "                #print(\"Syn:\",syn)\n",
    "                #print(\"la fase es:\",fases[i])\n",
    "                #print(\"---------------------------------------------------------------------------------------\")\n",
    "\n",
    "                    cont=1\n",
    "                    if path2 is not None:\n",
    "                        file.write(\"\\t\"+str(\"%.3f\"%fases[i])+\"\\t\"+str(\"%.3e\"%((syn)))+\"\\t\"+ \n",
    "                                                    str(0)+\"\\t\"+str(\"F\")+\"\\t\"+\n",
    "                                                    \"nan\"+\"\\t\"+\"nan\"+\"\\t\"+\"nan\"+\n",
    "                                                        \"\\n\")\n",
    "\n",
    "\n",
    "                else:\n",
    "                    #print (\"EL PORCENTAJE DE LA BANDA \"+str(bandas_con_curvas[q]) +\" ES DE :\",porcentaje*100)\n",
    "                    #print(\"NO CUMPLE EL MINIMO\")\n",
    "                    #print(\"---------------------------------------------------------------------------------------\")\n",
    "\n",
    "                    continue\n",
    "\n",
    "\n",
    "           \n",
    "            LC_df=pd.DataFrame({'mjd':np.array(la),'flux':np.array(le),'flux_err':np.zeros(len(la)),3:['F']*len(la),'band':filtros[q]})\n",
    "            \n",
    "            if do_plot==True:\n",
    "                if len(le)!=0:\n",
    "                    fig = plt.figure(figsize=(7,5))\n",
    "                    ax= fig.add_subplot(111)\n",
    "                    ax.plot(la,le,\".\") #le es la flujo, solo le puse ese nombre porque se me acaban los nombres\n",
    "                    plt.title(name+\" \"+filtros[q])\n",
    "                    #ax.plot(la,new_fluxes,'x',color='black')\n",
    "                    plt.gca().invert_yaxis()\n",
    "                    plt.show()\n",
    "            #pdf.savefig(fig,bbox_inches='tight')\n",
    "            if len(LC_df)!=0:\n",
    "                LC_list.append(LC_df)\n",
    "    \n",
    "\n",
    "    return LC_list      \n",
    "            #df_projected=field_projection(np.array(la),new_fluxes,df_obslog,tipo,selected_filter,selected_field,offset,name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_redeening(sn,ESPECTRO,fases,ebmv=None,mu=None,z=None,path_save='',reverse=False,to_abs_mag=False,write=False,use_DL=False,ubuntu=False):\n",
    "    '''\n",
    "    El codigo busca el archivo modulus donde esta toda la info de las SN\n",
    "    sn_list: lista de las SN con la extension para leerlas, ex ['SN2005cs.dat','SN2013ej.dat']\n",
    "    names: Lista con los nombres de la SN sin la extencion, para buscar el nombre en archivo modulus\n",
    "    path_save: path donde se guarda el nuevo espectro, solos si write ==True\n",
    "    reverse: Si es False, corrigue por reddening, si es True, Agrega el reddening (proceso inverso)\n",
    "    to_abs_mag= Si es True, lleva todo a magnitud absoluta o corrigue por ella\n",
    "\n",
    "    '''\n",
    "\n",
    "    if ubuntu==True:\n",
    "        G_path='/mnt/g/Mi unidad'\n",
    "    else:\n",
    "        G_path=\"G:\\Mi unidad\"\n",
    "    modulus_path=os.path.join(G_path,'Work','Universidad','Phd','DATA_OSC','all_data',' .cvs')\n",
    "    modulus=pd.read_csv(modulus_path)\n",
    "\n",
    "    print(sn)\n",
    "    name=sn\n",
    "    NEW_ESPECTRO=[]\n",
    "    if mu ==None:\n",
    "        mu=float(modulus[modulus['Sn']==name]['modulus'])\n",
    "    else:\n",
    "        mu=mu\n",
    "    if ebmv==None:\n",
    "        ebmv=float(modulus[modulus['Sn']==name]['ebmv'])\n",
    "        \n",
    "        \n",
    "        #if ebmv\n",
    "        #random.choice(distribution)\n",
    "        \n",
    "    else:\n",
    "        ebmv=ebmv\n",
    "    if z!=None:\n",
    "        z=z\n",
    "    else:\n",
    "        z=float(modulus[modulus['Sn']==name]['z'])\n",
    "    print(\"E(B-v),Z,mu\")\n",
    "    print(ebmv,z,mu)\n",
    "    \n",
    "    for i in range(len(ESPECTRO)):\n",
    "        \n",
    "        df=pd.DataFrame({'wave':ESPECTRO[i].wave,'flux':ESPECTRO[i].flux})\n",
    "        \n",
    "        df = df.reset_index(drop=True)\n",
    "        #print(i,df)\n",
    "        \n",
    "        \n",
    "        if reverse==False:\n",
    "            #--------correguimos por redshift, esto le saca el redshift original--------.\n",
    "            df['wave']=df['wave']/(1+z)\n",
    "    \n",
    "            #-------------------correguimos por reddenig de la MW-----------\n",
    "        \n",
    "            new_spectro=redden_spectrum_adjusted(ESPECTRO[i].wave,ESPECTRO[i].flux,Rv=3.1,ebmv=ebmv)\n",
    "        \n",
    "            df['flux']=new_spectro\n",
    "\n",
    "            #llevamos el flujo a una distancia comun de 10pc para posteriores usos. la formula F10=(d[pc]/10[pc])^2 * Flujo_actual\n",
    "            #primero sacamos la distancia en parsec con el modulo de distancia--------------\n",
    "            if to_abs_mag==True:\n",
    "                d_pc=10**((mu+5)/5) #distancia en parsec\n",
    "\n",
    "                df['flux']=df['flux']*((d_pc/10)**2)\n",
    "\n",
    "            #regrillamos\n",
    "            xnew=np.arange(int(min(df.wave)),max(df.wave)+1,1)\n",
    "            interpolated_flux = interpolate.interp1d(df.wave,df.flux,fill_value = \"extrapolate\")\n",
    "            \n",
    "            new_df = pd.DataFrame({'wave': xnew,'flux':interpolated_flux(xnew)})\n",
    "\n",
    "\n",
    "\n",
    "        if reverse==True: #aplicamos todos los procesos de manera inversa.\n",
    "            if to_abs_mag==True and use_DL==False:\n",
    "                d_pc=10**((mu+5)/5) #distancia en parsec\n",
    "                df['flux']=df['flux']/((d_pc/10)**2) #correguimos la magnitud absoluta\n",
    "            if to_abs_mag==False and use_DL==True:\n",
    "                DL=DL_calculator(z)\n",
    "                \n",
    "                if z!=0:\n",
    "                    df['wave']=df['wave']*(1+z)\n",
    "                    df['flux']=df['flux'] * ((1e-5 /DL)**2) #el 1e-5 son 10pc, los pasamos a Mpc para que tenga las mimas unidades de DL, Fobs= Fem*(1e-5/DL)^2\n",
    "            if to_abs_mag==True and use_DL==True:\n",
    "                print('No puedes usar to_abs_mag=True y use_DL True al mismo tiempo\\nporfavor decide si correguir por mag abs (modulo de distancia) o llevar a un nuevo redshift y calcular DL')\n",
    "                return None,None\n",
    "            new_spectro=redden_spectrum_adjusted(df.wave,df.flux,Rv=3.1,ebmv=-ebmv)\n",
    "            df['flux']=new_spectro\n",
    "            if use_DL==False:\n",
    "                df['wave']=df['wave']*(1+z)\n",
    "            \n",
    "\n",
    "            #regrillamos\n",
    "            #print(int(min(df.wave)),max(df.wave)+1)\n",
    "            xnew=np.arange(int(min(df.wave)),max(df.wave)+1,1)\n",
    "            interpolated_flux = interpolate.interp1d(df.wave,df.flux,fill_value = \"extrapolate\")\n",
    "            \n",
    "            new_df = pd.DataFrame({'wave': xnew,'flux':interpolated_flux(xnew)})\n",
    "\n",
    "        \n",
    "        \n",
    "        NEW_ESPECTRO.append(new_df)\n",
    "    \n",
    "    if write==True:\n",
    "        write_spetra(NEW_ESPECTRO,fases,os.path.join(path_save,sn))\n",
    "\n",
    "            \n",
    "\n",
    "    \n",
    "    return NEW_ESPECTRO,fases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_constantes={\n",
    " 'cteB': 6.460803024157998e-09,\n",
    " 'cteV': 3.67558126207669e-09,\n",
    " 'cteR': 2.2319872881446082e-09,\n",
    " 'cteI': 1.1769629663231628e-09,\n",
    " 'cteU': 4.346809582387867e-09,\n",
    " 'cteu': 9.512689427618875e-09,\n",
    " 'cteg': 4.791168585588861e-09,\n",
    " 'cter': 2.818556152283821e-09,\n",
    " 'ctei': 1.9069984363571034e-09,\n",
    " 'ctez': 1.413365541656362e-09\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mangle_iteration_function(spec_df,fase_float,ratios_df,plot=False,return_fig=False):\n",
    "\n",
    "    min_scale=0.1#min_scale=5*10**-3\n",
    "    optimization=False#optimization=True\n",
    "\n",
    "    ext_spec=spec_df\n",
    "    ratios_df=ratios_df\n",
    "    wls_eff = np.array(ratios_df.longitud_efectiva)\n",
    "    used_filters = np.array(ratios_df.banda)\n",
    "    fase_float=fase_float\n",
    "    ratios_0=ratios_df.ratio\n",
    "    # 1st iteration        \n",
    "\n",
    "\n",
    "    mang_mask, mang_mask_err = GP_interpolation_mangle(spec_df,ratios_df,optimization=True)\n",
    "\n",
    "    mangled_spec = ext_spec['flux'] / mang_mask\n",
    "    mangled_spec_err = ((ext_spec['flux'] * mang_mask_err)**2)**0.5\n",
    "\n",
    "    smangled_spec = {0 : np.array([a for a in zip(ext_spec['wave'],\n",
    "                                                        mangled_spec, mangled_spec_err)],\n",
    "                                    dtype=[('wave', '<f8'), ('flux', '<f8'), ('fluxerr', '<f8')])}\n",
    "    smangled_spec=pd.DataFrame(smangled_spec[0]) #lo convierto a df\n",
    "    mangling_mask = {0 : (mang_mask, mang_mask_err) }\n",
    "\n",
    "\n",
    "    #ahora que tengo la funcion de mangleo y mi espectro mangleado, calculare de nuevo la fotometria sintetica\n",
    "    #para poder sacar de nuevo los ratios\n",
    "    mangled_phot_list=[]\n",
    "\n",
    "    #for filt in used_filters:\n",
    "        #aqui al parecer calcula de nuevo la fotometria pero en el espectro mangleado\n",
    "    syn_phot_list=compute_lc([smangled_spec],[fase_float],used_filters,name)\n",
    "    syn_phot_df=pd.concat([df for df in syn_phot_list], ignore_index=True)\n",
    "\n",
    "\n",
    "    z_p_list=[]\n",
    "    for banda in syn_phot_df['band']:\n",
    "        z_p_str='cte'+banda\n",
    "        z_p_value=dic_constantes[z_p_str]\n",
    "        #print(banda,z_p_value)\n",
    "        z_p_list.append(z_p_value)\n",
    "    z_p_list=np.array(z_p_list)\n",
    "\n",
    "    #for filt in used_filters:\n",
    "    #    mangled_phot_list.append(band_flux(filt, use_what=0)[1])\n",
    "    #magled_photometry_dict = {0 : {'eff_wls': wls_eff, \n",
    "    #                                        'fitted_phot': mangled_phot_list,\\\n",
    "    #                                    'used_filters': used_filters}}\n",
    "\n",
    "\n",
    "    fig=plt.figure(1, figsize=(14,6))\n",
    "    plt.rc('font', family='serif')\n",
    "    plt.rc('xtick', labelsize=13)\n",
    "    plt.rc('ytick', labelsize=13)\n",
    "    ax1 = plt.subplot2grid((5,1), (0,0), rowspan=2)\n",
    "    ratios_err=ratios_df.ratio*0.01\n",
    "    for f,w,r,rerr in zip(used_filters, wls_eff,\\\n",
    "                            ratios_df.ratio, ratios_err):\n",
    "\n",
    "        flabel = f\n",
    "        ax1.errorbar(w, r, yerr=rerr, marker=\"^\", ms=8,\n",
    "                        mfc= 'red', mec='green', linestyle='None',\\\n",
    "                    ecolor= 'black', label='%s'%flabel)\n",
    "    ax1.errorbar(smangled_spec['wave'], mang_mask, color='green',label='Mangling\\nfunction')\n",
    "    ax1.fill_between(smangled_spec['wave'], mang_mask-mang_mask_err, mang_mask+mang_mask_err, color='green',alpha=0.3)\n",
    "    ax1.set_ylabel('Synthetic Flux/\\nPhotometric Flux', fontsize=13)\n",
    "    firts_mangled=mang_mask.copy()\n",
    "    fase_float_title=fase_float-float(maximo_lc(tipo,name))\n",
    "    ax1.set_title(' %s'%name+'  '+str(fase_float_title) ,fontsize=15)\n",
    "\n",
    "    #ax1.set_ylim(min(ratios)*(0.9), max(ratios)*(1.1))\n",
    "    #ax1.set_xlim(1600., 10300.)\n",
    "    plt.tick_params(axis='x', labelbottom=False)\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "    #calculamos los ratios actuales\n",
    "    ratios_it_df=compute_ratios(smangled_spec,fase_float,used_filters,all_FILTROS_real)\n",
    "\n",
    "    ax2 = plt.subplot2grid((5,1), (2,0), rowspan=3)\n",
    "\n",
    "    ax2.errorbar(smangled_spec['wave'], smangled_spec['flux'],\\\n",
    "                    lw=0.9, color='green', label='Mangled Spectrum')\n",
    "    #mask_neg = mangled_spec['flux']<0.\n",
    "    #ax2.errorbar(mangled_spec['wave'][mask_neg], mangled_spec['flux'][mask_neg],\\\n",
    "    #                lw=3.9, color='green', label='Mangled Spectrum 2')\n",
    "\n",
    "    ax2.errorbar(ext_spec['wave'], ext_spec['flux'],\\\n",
    "                    lw=0.6, color='blue', alpha=1, label=' Spectrum')\n",
    "\n",
    "    ax2.errorbar(ratios_df.longitud_efectiva,ratios_df.syn_phot*z_p_list,\\\n",
    "                    marker='^', mfc='yellow', mec='black', linestyle='None', ms=9,\n",
    "                    label='Flux before mangled spec')\n",
    "    ax2.errorbar(ratios_df.longitud_efectiva, ratios_it_df.syn_phot*z_p_list,\\\n",
    "                    marker='^', mfc='red', mec='black', linestyle='None', ms=9,\n",
    "                    label='Flux from mangled spec')\n",
    "\n",
    "    ax2.errorbar(ratios_df.longitud_efectiva,ratios_df.real_phot*z_p_list,\\\n",
    "                    marker='^', mfc='blue', mec='black', linestyle='None', ms=9,\n",
    "                    label='Photometric flux')\n",
    "    '''\n",
    "    ax2.errorbar(np.concatenate([fitted_phot_dict['eff_wls'],outwls_filters_wls_eff]), \n",
    "                    np.concatenate([fitted_phot_dict['fitted_phot'], outwls_fitted_phot_list]),\\\n",
    "                    yerr = np.concatenate([fitted_phot_dict['fitted_phot_err'], \n",
    "                                        outwls_fitted_photerr_list]),\n",
    "                    marker='o', mfc='blue', mec='grey',ms=9, \n",
    "                    ecolor='blue', linestyle='None', label='Photometric flux')\n",
    "            \n",
    "    ax2.fill_between(mangled_spec['wave'], mangled_spec['flux']-mangled_spec['fluxerr'],\\\n",
    "                        mangled_spec['flux']+mangled_spec['fluxerr'], color='green',alpha=0.3)\n",
    "\n",
    "    '''\n",
    "\n",
    "    ax2.set_ylabel(r'Flux ($\\mathrm{erg}$ $\\mathrm{s^{-1} cm^{-2}} \\mathrm{\\AA} $)', fontsize=13)\n",
    "    ax2.set_xlabel(r'Wavelength ($\\mathrm{\\AA}$)', fontsize=13)\n",
    "    #ax2.set_xlim(1600., 10300.)\n",
    "    ax2.legend(ncol=1, fontsize=9, loc='upper right')\n",
    "    plt.subplots_adjust(hspace=0.3, wspace=0.1)\n",
    "    #fig.savefig(mangledspec_path+'%.2f_mangled_spec.pdf'%spec_number, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # More iterations\n",
    "    ratios = ratios_0\n",
    "    max_iteration = 5\n",
    "    for i in range(max_iteration):\n",
    "        if max(np.abs(ratios-1.))>0.01:\n",
    "            #print (i)\n",
    "\n",
    "            mang_mask, mang_mask_err = GP_interpolation_mangle(smangled_spec,ratios_it_df,optimization=True)\n",
    "            #print ('iteration', i,ratios_iter)\n",
    "            smangled_spec['flux'] = smangled_spec['flux'] / mang_mask\n",
    "            #mangled_spec_err = ( (self.mangled_spec[str(i+1)]['flux'] * mang_mask_err)**2 +\\\n",
    "            #            (self.mangled_spec[str(i+1)]['fluxerr'] * mang_mask)**2 )**0.5\n",
    "            smangled_spec['fluxerr'] = (smangled_spec['fluxerr'] * mang_mask_err)\n",
    "\n",
    "            #print ('save new', (i+1))\n",
    "            #esto solo lo convierte a diccionario\n",
    "            #self.mangled_spec[i+1] = np.array([a for a in zip(self.ext_spec['wls'], \n",
    "            #                                                        mangled_spec, mangled_spec_err)],\n",
    "            #                            dtype=[('wls', '<f8'), ('flux', '<f8'), ('fluxerr', '<f8')])\n",
    "            \n",
    "            mangling_mask[i+1] = (mang_mask, mang_mask_err)\n",
    "            mangled_phot_list=[]\n",
    "            #calculamos la fotometria syn del espectro mangleado\n",
    "            ratios_it_df=compute_ratios(smangled_spec,fase_float,used_filters,all_FILTROS_real)\n",
    "\n",
    "\n",
    "            ratios = np.copy(ratios_it_df.ratio)\n",
    "            ratios_err = np.array(ratios_it_df.ratio)*0.01\n",
    "\n",
    "            \n",
    "        \n",
    "\n",
    "            #ploteamos\n",
    "            \n",
    "            if plot==True or i==4:\n",
    "                fig=plt.figure(2, figsize=(14,6))\n",
    "                plt.rc('font', family='serif')\n",
    "                plt.rc('xtick', labelsize=13)\n",
    "                plt.rc('ytick', labelsize=13)\n",
    "                ax1 = plt.subplot2grid((5,1), (0,0), rowspan=2)\n",
    "                for f,w,r,rerr in zip(used_filters, wls_eff,\\\n",
    "                                        ratios, ratios_err):\n",
    "\n",
    "                    flabel = f\n",
    "                    ax1.errorbar(w, r, yerr=rerr, marker=\"^\", ms=8,\n",
    "                                    mfc= 'red', mec='green', linestyle='None',\\\n",
    "                                ecolor= 'black', label='%s'%flabel)\n",
    "                ax1.errorbar(smangled_spec['wave'], firts_mangled, color='gray',label='First Mangling\\nfunction')\n",
    "\n",
    "                ax1.errorbar(smangled_spec['wave'], mang_mask, color='green',label='Mangling\\nfunction')\n",
    "                ax1.fill_between(smangled_spec['wave'], mang_mask-mang_mask_err, mang_mask+mang_mask_err, color='green',alpha=0.3)\n",
    "                ax1.set_ylabel('Synthetic Flux/\\nPhotometric Flux', fontsize=13)\n",
    "\n",
    "                ax1.set_title('Last iteration'+' %s'%name+'  '+str(fase_float_title) ,fontsize=15)\n",
    "\n",
    "                #ax1.set_ylim(min(ratios)*(0.9), max(ratios)*(1.1))\n",
    "                #ax1.set_xlim(1600., 10300.)\n",
    "                plt.tick_params(axis='x', labelbottom=False)\n",
    "                ax1.legend(fontsize=7)\n",
    "\n",
    "                ax2 = plt.subplot2grid((5,1), (2,0), rowspan=3)\n",
    "\n",
    "                ax2.errorbar(smangled_spec['wave'], smangled_spec['flux'],\\\n",
    "                                lw=0.9, color='green', label='Mangled Spectrum')\n",
    "                #mask_neg = mangled_spec['flux']<0.\n",
    "                #ax2.errorbar(mangled_spec['wave'][mask_neg], mangled_spec['flux'][mask_neg],\\\n",
    "                #                lw=3.9, color='green', label='Mangled Spectrum 2')\n",
    "\n",
    "                ax2.errorbar(ext_spec['wave'], ext_spec['flux'],\\\n",
    "                                lw=0.6, color='blue', alpha=1, label=' Spectrum')\n",
    "                \n",
    "                ax2.errorbar(ratios_df.longitud_efectiva,ratios_df.syn_phot*z_p_list,\\\n",
    "                        marker='^', mfc='yellow', mec='black', linestyle='None', ms=9,\n",
    "                        label='Flux before mangled spec')\n",
    "                \n",
    "                ax2.errorbar(ratios_df.longitud_efectiva, ratios_it_df.syn_phot*z_p_list,\\\n",
    "                        marker='^', mfc='red', mec='black', linestyle='None', ms=9,\n",
    "                        label='Flux from mangled spec')\n",
    "                \n",
    "                ax2.errorbar(ratios_df.longitud_efectiva,ratios_df.real_phot*z_p_list,\\\n",
    "                        marker='^', mfc='blue', mec='black', linestyle='None', ms=9,\n",
    "                        label='Photometric flux')\n",
    "                plt.legend(fontsize=7)\n",
    "                plt.show()\n",
    "\n",
    "                #print ('last_iter', last_iter)\n",
    "                #final_mangled_spec = smangled_spec\n",
    "                #spec_number = self.phot4mangling.spec_mjd.values[0]#self.phot4mangling.index.values[0]\n",
    "\n",
    "        \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        smangled_spec\n",
    "        #self.save_mangled_spectrum()\n",
    "    if return_fig==True:\n",
    "        return smangled_spec,fig \n",
    "    return smangled_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GP_interpolation_mangle(spec_df,ratios_df,optimization=True):\n",
    "    import scipy.optimize as opt\n",
    "    import george\n",
    "    from george.kernels import ExpSquaredKernel, ConstantKernel, Matern32Kernel\n",
    "\n",
    "\n",
    "    ext_spec=spec_df\n",
    "    wls_eff=ratios_df.longitud_efectiva\n",
    "    ratios=ratios_df.ratio\n",
    "    ratios_err=ratios*0.01\n",
    "    optimization=True\n",
    "\n",
    "\n",
    "    if len(ext_spec['wave'])>10**4:\n",
    "                # GP struggle to handle such a big number of points\n",
    "                int_fraction = int(len(ext_spec['wave'])/5000.)\n",
    "                print ('This spectrum has a huge amount of data points(%i), Im chopping a %i th of them'%(len(ext_spec['wave']), int_fraction))\n",
    "                full_wls = ext_spec['wave'][::int_fraction]\n",
    "    else:\n",
    "        full_wls = ext_spec['wave']\n",
    "\n",
    "\n",
    "    norm_wls = np.median(full_wls)\n",
    "    full_wls_normed = full_wls/norm_wls\n",
    "    wls_eff_normed = np.array(wls_eff)/norm_wls\n",
    "        \n",
    "    offset=1.\n",
    "    norm = np.mean(ratios)\n",
    "    ratios_normed = np.array(ratios)/norm-offset\n",
    "    ratios_err_normed = np.array(ratios_err)/norm\n",
    "\n",
    "    if len(ratios_normed)<1:\n",
    "        print (np.ones(len(full_wls_normed))*np.nan, np.ones(len(full_wls_normed))*np.nan)\n",
    "    else:\n",
    "        def ll(p):\n",
    "            #print (np.exp(p))\n",
    "            if (np.exp(p)[1]<5*10**-3):#|(np.exp(p)[1]>10**5):\n",
    "                return np.inf\n",
    "            else:\n",
    "                gp.set_parameter_vector(p)\n",
    "                return -gp.lnlikelihood(ratios_normed, quiet=False)#\n",
    "        def grad_ll(p):\n",
    "            gp.set_parameter_vector(p)\n",
    "            return -gp.grad_lnlikelihood(ratios_normed, quiet=False)\n",
    "\n",
    "        def ll(p):\n",
    "            gp.set_parameter_vector(p)\n",
    "            scale = np.exp(gp.get_parameter_dict()['kernel:k2:metric:log_M_0_0'])\n",
    "            if scale<0.09:\n",
    "                return np.inf\n",
    "            else:\n",
    "                return -gp.lnlikelihood(ratios_normed, quiet=False)#\n",
    "        \n",
    "        k= np.var(ratios_normed)*Matern32Kernel(0.3)\n",
    "        wls_eff_normedT = np.atleast_2d(wls_eff_normed).T\n",
    "        #print(wls_eff_normedT)\n",
    "        gp = george.GP(k)\n",
    "        gp.compute(wls_eff_normedT, (ratios_err_normed))\n",
    "        if optimization:\n",
    "            try:\n",
    "                p0=gp.get_parameter_vector()\n",
    "                results = opt.minimize(ll, p0, jac=grad_ll)\n",
    "                print ('SCALE:',  '%.4f'%np.exp(results.x[1]))\n",
    "            except:\n",
    "                pass\n",
    "                print ('*** GP optimization failed ***'*10)\n",
    "        #print (results)\n",
    "        gp.set_parameter_vector(results.x)\n",
    "        mu, cov = gp.predict(ratios_normed, full_wls_normed)\n",
    "        std = np.sqrt(np.diag(cov))\n",
    "            \n",
    "        if len(ext_spec['wave'])>10**4:\n",
    "            # GP struggle to handle such a big number of points\n",
    "            mu_full = np.interp(ext_spec['wave'], ext_spec['wave'][::int_fraction], mu)\n",
    "            std_full = np.interp(ext_spec['wave'], ext_spec['wave'][::int_fraction], std)\n",
    "        else:\n",
    "            mu_full = mu\n",
    "            std_full = std\n",
    "\n",
    "    \n",
    "    #retorna la funcion de mangleo y el error asocaido\n",
    "    return norm*(mu_full+offset), np.abs(norm*(std_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ratios(spec_df,fase_float,filtros_real,all_FILTROS_real,delete_filter=[]):\n",
    "       '''\n",
    "       spec_ : spectro como dataframe, wave,flux\n",
    "       fase_: float de la fase\n",
    "       filtros_real: filtros de la fotometria real que esta en FILTROS_REAL\n",
    "       all_FILTROS_real:  Dataframe con todas las curvas de luces en todas las bandas\n",
    "\n",
    "       resumen: el codigo calcula la fotometria sintetica del espectro para todas las bandas en la lista filtros,\n",
    "       despues itera sobre todas las banas de filtros real para calcular los ratios\n",
    "\n",
    "       return: retorna un df con los ratios por banda y la longitud efectiva\n",
    "       '''\n",
    "       #para eso usamos la funcion compute_lighcurve, calculamos sobre todos los filtros que hay en real\n",
    "       #syn_phto aqu es una lista, con los dataframes de la banda que les corresponde\n",
    "       syn_phot_list=compute_lc([spec_df],[fase_float],filtros_real,name)\n",
    "       syn_phot_df=pd.concat([df for df in syn_phot_list], ignore_index=True) #pasamos a pandas porq es mas facil de manejar\n",
    "\n",
    "       #ahora que tengo la sintetica para todos los filtros, calculo el ratio\n",
    "       ratios_data = {'banda': [], 'real_phot': [],'syn_phot': [],'ratio': [], 'longitud_efectiva': []}\n",
    "\n",
    "       for band in filtros_real:\n",
    "              try:\n",
    "                     real_phot=float(all_FILTROS_real.loc[(all_FILTROS_real['mjd']==fase_float) & (all_FILTROS_real['band']==band) ].flux)\n",
    "              except: #por si no hay fotometria real no se puede calcualr K\n",
    "                     continue\n",
    "              syn_phot=syn_phot_df.loc[syn_phot_df['band']==band].flux #la phot de una badna especifica para calcular ratio\n",
    "              if len(syn_phot)==0:\n",
    "                     continue\n",
    "              else:\n",
    "                     syn_phot=float(syn_phot)\n",
    "\n",
    "              #ahora que tenemos ambas calculamos el ratio\n",
    "              #pasamos a flujo para hacer el cociente\n",
    "              syn_phot=10**(-0.4*syn_phot)\n",
    "              real_phot=10**(-0.4*real_phot)\n",
    "              ratio=syn_phot/real_phot\n",
    "\n",
    "              \n",
    "              longitudes_efectivas={\n",
    "              'U': 3600.0,\n",
    "              'B': 4380.0,\n",
    "              'V': 5450.0,\n",
    "              'R': 6410.0,\n",
    "              'I': 7980.0,\n",
    "              'u': 3560.0,\n",
    "              'g': 4830.0,\n",
    "              'r': 6260.0,\n",
    "              'i': 7670.0,\n",
    "              'z': 9100.0\n",
    "              }\n",
    "\n",
    "              # Añadiendo los datos al diccionario\n",
    "              ratios_data['banda'].append(band)\n",
    "              ratios_data['real_phot'].append(real_phot)\n",
    "              ratios_data['syn_phot'].append(syn_phot)\n",
    "              ratios_data['ratio'].append(ratio)\n",
    "              ratios_data['longitud_efectiva'].append(longitudes_efectivas[band])\n",
    "\n",
    "\n",
    "\n",
    "       df_ratios = pd.DataFrame(ratios_data)\n",
    "       df_filtrado = df_ratios[~df_ratios['banda'].isin(delete_filter)]\n",
    "\n",
    "       df_filtrado=df_filtrado.sort_values(by='longitud_efectiva').reset_index(drop=True)\n",
    "\n",
    "       return df_filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "def DL_calculator(z,H0=69.6,WM=0.286,WV=0.714):\n",
    "    \"\"\"\n",
    "    Funcion para calcular DL a partir de un redshift y ciertos parametros cosmologicos\n",
    "    Si ningun parametros cosmologico es ingresado, se usan los por defecto de https://www.astro.ucla.edu/~wright/CosmoCalc.html\n",
    "\n",
    "    \"\"\"\n",
    "    c = 299792.458 # Velocidad de la luz en km/s\n",
    "    h = H0/100.\n",
    "    WR = 4.165E-5/(h*h)   # includes  3 massless neutrino species, T0 = 2.72528\n",
    "    WK = 1-WM-WR-WV\n",
    "    az = 1.0/(1+1.0*z)\n",
    "    age = 0.\n",
    "    n=1000         # number of points in integrals\n",
    "    DCMR = 0.0\n",
    "    \n",
    "    # do integral over a=1/(1+z) from az to 1 in n steps, midpoint rule\n",
    "    for i in range(n):\n",
    "        a = az+(1-az)*(i+0.5)/n\n",
    "        adot = sqrt(WK+(WM/a)+(WR/(a*a))+(WV*a*a))\n",
    "        #DTT = DTT + 1./adot\n",
    "        DCMR = DCMR + 1./(a*adot)\n",
    "\n",
    "    DCMR = (1.-az)*DCMR/n\n",
    "    ratio = 1.00\n",
    "    x = sqrt(abs(WK))*DCMR #si el universo es plano x=0 y no entra, por lo tanto el ratio es 1, ya que \"y\" tambien seria 0                             \n",
    "    if x > 0.1:\n",
    "        if WK > 0:\n",
    "            ratio =  0.5*(exp(x)-exp(-x))/x \n",
    "        else:\n",
    "            ratio = sin(x)/x\n",
    "    else:\n",
    "        y = x*x\n",
    "    if WK < 0: y = -y\n",
    "    ratio = 1. + y/6. + y*y/120.\n",
    "\n",
    "    DCMT = ratio*DCMR\n",
    "    DA = az*DCMT\n",
    "    DL = DA/(az*az)\n",
    "    DL_Mpc = (c/H0)*DL\n",
    "    return DL_Mpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_constantes={\n",
    " 'cteB': 6.460803024157998e-09,\n",
    " 'cteV': 3.67558126207669e-09,\n",
    " 'cteR': 2.2319872881446082e-09,\n",
    " 'cteI': 1.1769629663231628e-09,\n",
    " 'cteU': 4.346809582387867e-09,\n",
    " 'cteu': 9.512689427618875e-09,\n",
    " 'cteg': 4.791168585588861e-09,\n",
    " 'cter': 2.818556152283821e-09,\n",
    " 'ctei': 1.9069984363571034e-09,\n",
    " 'ctez': 1.413365541656362e-09\n",
    "}\n",
    "\n",
    "'''\n",
    "#pasamos a mag\n",
    "arr_ctes=['cteB','cteV','cteR','cteI','cteU','cteu','cteg','cter','ctei','ctez']\n",
    "arr_val_ctes=[cteB,cteV,cteR,cteI,cteU,cteu,cteg,cter,ctei,ctez]\n",
    "V=filtros[q]\n",
    "constante='cte'+V #pongo V pero es cualquier banda\n",
    "#print (constante)\n",
    "for jj in range(len(arr_ctes)): \n",
    "    if constante==arr_ctes[jj]: #recorremos el arreglo de constantes en busca de la que le corresponde\n",
    "        #print (constante,arr_ctes[jj],arr_val_ctes[jj])\n",
    "        mul=arr_val_ctes[jj]\n",
    "    \n",
    "mag=-2.5*np.log10(syn/mul)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
